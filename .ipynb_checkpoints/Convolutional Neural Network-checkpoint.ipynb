{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import librosa\n",
    "import keras\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, Input\n",
    "from keras.layers import Conv2D,Conv2DTranspose\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import keras.layers.advanced_activations\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import image\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import csv\n",
    "import pathlib\n",
    "import os\n",
    "import sys\n",
    "from PIL import Image\n",
    "sys.modules['Image'] = Image\n",
    "import IPython.display as ipd\n",
    "from IPython.display import display, Image\n",
    "from IPython.display import display\n",
    "from sklearn.preprocessing import  LabelEncoder, StandardScaler, normalize\n",
    "from sklearn.decomposition import PCA\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "logdir=\"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#https://www.analyticsvidhya.com/blog/2019/08/3-techniques-extract-features-from-image-data-machine-learning-python/\n",
    "#https://stackoverflow.com/questions/45708460/how-extract-numpy-array-features-from-spectrogram\n",
    "#https://github.com/andyharless/paces\n",
    "#https://towardsdatascience.com/sound-classification-using-images-68d4770df426\n",
    "#https://towardsdatascience.com/machine-learning-and-music-classification-a-content-based-filtering-approach-f2c4eb13bade\n",
    "# cmap = plt.get_cmap('inferno')\n",
    "\n",
    "# plt.figure(figsize=(10,10))\n",
    "# genres = 'blues classical country disco hiphop jazz metal pop reggae rock'.split()\n",
    "# for g in genres:\n",
    "#     pathlib.Path(f'img_data/{g}').mkdir(parents=True, exist_ok=True) \n",
    "#     for filename in os.listdir(f'./genres/{g}'):\n",
    "#         songname = f'./genres/{g}/{filename}'\n",
    "#         y, sr = librosa.load(songname, mono=True, duration=5)\n",
    "#         plt.specgram(y, NFFT=2048, Fs=2, Fc=0, noverlap=128, cmap=cmap, sides='default', mode='default', scale='dB');\n",
    "#         plt.axis('off');\n",
    "#         plt.savefig(f'img_data/{g}/{filename[:-3].replace(\".\", \"\")}.png')\n",
    "#         plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genres = 'blues classical country disco hiphop jazz metal pop reggae rock'.split()\n",
    "# photo_img = []\n",
    "# for g in genres:\n",
    "#     for filename in os.listdir(f'./img_data/{g}'): \n",
    "#         images = f'./img_data/{g}/{filename}'\n",
    "        \n",
    "#         for i in range(len((images))):\n",
    "#             path1 = images[i]\n",
    "            \n",
    "#             temp = image.load_img(path1, target_size=(128, 128, 3))\n",
    "#             temp = image.img_to_array(temp)\n",
    "#             photo_img.append(temp)\n",
    "            \n",
    "#         photo_img = np.array(photo_img)\n",
    "#         photo_img = photo_img.astype('float32')\n",
    "#         photo_img = (photo_img.astype(np.float) - 127.5) / 127.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We’ll process dataset as per our requirements. \n",
    "#We’ll create a CSV file with the data we required.\n",
    "header = 'Filename Chromagram RootMeanSquare LowEnergyBrightness SpectralCentroid Flatness Bandwidth InHarmonicity Rolloff ZeroCrossingRate'\n",
    "for i in range(1,21):\n",
    "        header += f' mfcc{i}'\n",
    "header += ' label'\n",
    "header = header.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoBackendError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\librosa\\core\\audio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0msf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSoundFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msf_desc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m             \u001b[0msr_native\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msf_desc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\soundfile.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[0;32m    626\u001b[0m                                          format, subtype, endian)\n\u001b[1;32m--> 627\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    628\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missuperset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'r+'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseekable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\soundfile.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[0;32m   1181\u001b[0m         _error_check(_snd.sf_error(file_ptr),\n\u001b[1;32m-> 1182\u001b[1;33m                      \"Error opening {0!r}: \".format(self.name))\n\u001b[0m\u001b[0;32m   1183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode_int\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_snd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSFM_WRITE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\soundfile.py\u001b[0m in \u001b[0;36m_error_check\u001b[1;34m(err, prefix)\u001b[0m\n\u001b[0;32m   1354\u001b[0m         \u001b[0merr_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_snd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msf_error_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1355\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0m_ffi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'replace'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error opening './images/blues/blues.00000.png': File contains data in an unknown format.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNoBackendError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-8de51d1f7da6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'./images/{g}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0msongname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf'./images/{g}/{filename}'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msongname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmono\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meffects\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mharmonic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mchroma_stft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchroma_stft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#chromagram\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\librosa\\core\\audio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'PySoundFile failed. Trying audioread instead.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr_native\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__audioread_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    148\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m             \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\librosa\\core\\audio.py\u001b[0m in \u001b[0;36m__audioread_load\u001b[1;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0maudioread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maudio_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0minput_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m         \u001b[0msr_native\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[0mn_channels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchannels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\audioread\\__init__.py\u001b[0m in \u001b[0;36maudio_open\u001b[1;34m(path, backends)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;31m# All backends failed!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mNoBackendError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNoBackendError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#If you have read the blog of features extraction \n",
    "#we’ll get 20 mfcc for given sampling rate because\n",
    "#it is calculated for each frame so mfcc has 20 columns.\n",
    "# #Now, we’ll calculate all the features.\n",
    "file = open('spectogramextractedmusicfeatureset2.csv', 'w', newline='')\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "genres = 'blues classical country disco hiphop jazz metal pop reggae rock'.split()\n",
    "for g in genres:\n",
    "    for filename in os.listdir(f'./images/{g}'):\n",
    "        songname = f'./images/{g}/{filename}'\n",
    "        y, sr = librosa.load(songname, mono=True, duration=30)\n",
    "        y = librosa.effects.harmonic(y)\n",
    "        chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)#chromagram\n",
    "        rms = librosa.feature.rms(y=y)#root-mean square\n",
    "        spec_cont = librosa.feature.spectral_contrast(y=y, sr=sr)#low energy/brightness\n",
    "        spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)#spectral centroid\n",
    "        spec_flat = librosa.feature.spectral_flatness(y=y)#flatness\n",
    "        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)#bandwidth\n",
    "        tone = librosa.feature.tonnetz(y=y, sr=sr)#In-Harmonicity\n",
    "        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)#rolloff\n",
    "        zcr = librosa.feature.zero_crossing_rate(y)#zero-crossing rate\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "        to_append = f'{filename} {np.mean(chroma_stft)} {np.mean(rms)} {np.mean(spec_cont)} {np.mean(spec_cent)} {np.mean(spec_flat)} {np.mean(spec_bw)} {np.mean(tone)} {np.mean(rolloff)} {np.mean(zcr)}'\n",
    "        for e in mfcc:\n",
    "            to_append += f' {np.mean(e)}'\n",
    "        to_append += f' {g}'\n",
    "        file = open('spectogramextractedmusicfeatureset.csv2', 'a', newline='')\n",
    "        with file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(to_append.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"spectogramextractedmusicfeatureset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 31)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Chromagram</th>\n",
       "      <th>RootMeanSquare</th>\n",
       "      <th>LowEnergyBrightness</th>\n",
       "      <th>SpectralCentroid</th>\n",
       "      <th>Flatness</th>\n",
       "      <th>Bandwidth</th>\n",
       "      <th>InHarmonicity</th>\n",
       "      <th>Rolloff</th>\n",
       "      <th>ZeroCrossingRate</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc12</th>\n",
       "      <th>mfcc13</th>\n",
       "      <th>mfcc14</th>\n",
       "      <th>mfcc15</th>\n",
       "      <th>mfcc16</th>\n",
       "      <th>mfcc17</th>\n",
       "      <th>mfcc18</th>\n",
       "      <th>mfcc19</th>\n",
       "      <th>mfcc20</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>blues.00000.wav</td>\n",
       "      <td>0.308197</td>\n",
       "      <td>0.082482</td>\n",
       "      <td>23.698370</td>\n",
       "      <td>1535.037572</td>\n",
       "      <td>0.001726</td>\n",
       "      <td>1834.035228</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>3175.514131</td>\n",
       "      <td>0.070391</td>\n",
       "      <td>...</td>\n",
       "      <td>6.815101</td>\n",
       "      <td>0.110116</td>\n",
       "      <td>4.418635</td>\n",
       "      <td>-1.796708</td>\n",
       "      <td>-1.787790</td>\n",
       "      <td>0.341001</td>\n",
       "      <td>-2.629384</td>\n",
       "      <td>-0.309009</td>\n",
       "      <td>-0.734714</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>blues.00001.wav</td>\n",
       "      <td>0.301338</td>\n",
       "      <td>0.064592</td>\n",
       "      <td>24.126800</td>\n",
       "      <td>1178.338976</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>1719.624593</td>\n",
       "      <td>0.018852</td>\n",
       "      <td>2425.427000</td>\n",
       "      <td>0.044456</td>\n",
       "      <td>...</td>\n",
       "      <td>2.652497</td>\n",
       "      <td>0.832175</td>\n",
       "      <td>2.269111</td>\n",
       "      <td>-4.967726</td>\n",
       "      <td>-1.012166</td>\n",
       "      <td>0.995347</td>\n",
       "      <td>-0.605718</td>\n",
       "      <td>1.565148</td>\n",
       "      <td>-0.685939</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>blues.00002.wav</td>\n",
       "      <td>0.296208</td>\n",
       "      <td>0.121434</td>\n",
       "      <td>25.195057</td>\n",
       "      <td>1303.581375</td>\n",
       "      <td>0.000763</td>\n",
       "      <td>1579.884288</td>\n",
       "      <td>0.022247</td>\n",
       "      <td>2479.285008</td>\n",
       "      <td>0.064793</td>\n",
       "      <td>...</td>\n",
       "      <td>4.676634</td>\n",
       "      <td>-7.930208</td>\n",
       "      <td>-5.197453</td>\n",
       "      <td>-8.683246</td>\n",
       "      <td>0.549078</td>\n",
       "      <td>-7.521339</td>\n",
       "      <td>-4.570396</td>\n",
       "      <td>-3.990504</td>\n",
       "      <td>-3.933193</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>blues.00003.wav</td>\n",
       "      <td>0.378564</td>\n",
       "      <td>0.117686</td>\n",
       "      <td>23.537749</td>\n",
       "      <td>765.650527</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>1289.465222</td>\n",
       "      <td>0.008652</td>\n",
       "      <td>1387.583276</td>\n",
       "      <td>0.024866</td>\n",
       "      <td>...</td>\n",
       "      <td>5.115472</td>\n",
       "      <td>0.440344</td>\n",
       "      <td>-1.861215</td>\n",
       "      <td>0.198612</td>\n",
       "      <td>1.217629</td>\n",
       "      <td>-0.756340</td>\n",
       "      <td>1.820389</td>\n",
       "      <td>-0.057328</td>\n",
       "      <td>-4.009497</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>blues.00004.wav</td>\n",
       "      <td>0.261476</td>\n",
       "      <td>0.060902</td>\n",
       "      <td>25.022190</td>\n",
       "      <td>1539.421609</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>1584.038983</td>\n",
       "      <td>-0.050764</td>\n",
       "      <td>2954.190470</td>\n",
       "      <td>0.085597</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.884608</td>\n",
       "      <td>-6.819392</td>\n",
       "      <td>-12.406286</td>\n",
       "      <td>-10.841472</td>\n",
       "      <td>-8.155150</td>\n",
       "      <td>-5.439511</td>\n",
       "      <td>-1.908890</td>\n",
       "      <td>-7.093715</td>\n",
       "      <td>-17.604401</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Filename  Chromagram  RootMeanSquare  LowEnergyBrightness  \\\n",
       "0  blues.00000.wav    0.308197        0.082482            23.698370   \n",
       "1  blues.00001.wav    0.301338        0.064592            24.126800   \n",
       "2  blues.00002.wav    0.296208        0.121434            25.195057   \n",
       "3  blues.00003.wav    0.378564        0.117686            23.537749   \n",
       "4  blues.00004.wav    0.261476        0.060902            25.022190   \n",
       "\n",
       "   SpectralCentroid  Flatness    Bandwidth  InHarmonicity      Rolloff  \\\n",
       "0       1535.037572  0.001726  1834.035228       0.000684  3175.514131   \n",
       "1       1178.338976  0.000634  1719.624593       0.018852  2425.427000   \n",
       "2       1303.581375  0.000763  1579.884288       0.022247  2479.285008   \n",
       "3        765.650527  0.000240  1289.465222       0.008652  1387.583276   \n",
       "4       1539.421609  0.001334  1584.038983      -0.050764  2954.190470   \n",
       "\n",
       "   ZeroCrossingRate  ...    mfcc12    mfcc13     mfcc14     mfcc15    mfcc16  \\\n",
       "0          0.070391  ...  6.815101  0.110116   4.418635  -1.796708 -1.787790   \n",
       "1          0.044456  ...  2.652497  0.832175   2.269111  -4.967726 -1.012166   \n",
       "2          0.064793  ...  4.676634 -7.930208  -5.197453  -8.683246  0.549078   \n",
       "3          0.024866  ...  5.115472  0.440344  -1.861215   0.198612  1.217629   \n",
       "4          0.085597  ... -6.884608 -6.819392 -12.406286 -10.841472 -8.155150   \n",
       "\n",
       "     mfcc17    mfcc18    mfcc19     mfcc20  label  \n",
       "0  0.341001 -2.629384 -0.309009  -0.734714  blues  \n",
       "1  0.995347 -0.605718  1.565148  -0.685939  blues  \n",
       "2 -7.521339 -4.570396 -3.990504  -3.933193  blues  \n",
       "3 -0.756340  1.820389 -0.057328  -4.009497  blues  \n",
       "4 -5.439511 -1.908890 -7.093715 -17.604401  blues  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.30819666,   0.08248157,  23.6983702 , ...,  -2.62938428,\n",
       "         -0.30900922,  -0.73471361],\n",
       "       [  0.30133769,   0.06459167,  24.12679967, ...,  -0.60571831,\n",
       "          1.56514776,  -0.6859386 ],\n",
       "       [  0.29620793,   0.12143367,  25.19505706, ...,  -4.57039595,\n",
       "         -3.99050379,  -3.93319345],\n",
       "       ...,\n",
       "       [  0.36632118,   0.06054005,  26.16334486, ...,   0.29160747,\n",
       "        -13.02284145,  -6.44119596],\n",
       "       [  0.32797623,   0.07178954,  25.97419752, ...,   0.1667455 ,\n",
       "         -4.40610647,  -5.59472847],\n",
       "       [  0.33593521,   0.04955495,  28.27949892, ...,  -1.13428056,\n",
       "         -0.38406467,   1.39163375]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Y = dataset['label']\n",
    "X = dataset\n",
    "X['numlabels'] = X['label'].astype('category').cat.codes\n",
    "X = dataset.drop(['Filename', 'label', 'numlabels'],axis=1) #Filename is not required\n",
    "Y = dataset['numlabels']\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Chromagram','RootMeanSquare','LowEnergyBrightness','SpectralCentroid','Flatness','Bandwidth','InHarmonicity','Rolloff','ZeroCrossingRate','mfcc1','mfcc2','mfcc3','mfcc4','mfcc5','mfcc6','mfcc7','mfcc8','mfcc9','mfcc10','mfcc11','mfcc12','mfcc13','mfcc14','mfcc15','mfcc16','mfcc17','mfcc18','mfcc19','mfcc20']\n",
    "# Separating out the features\n",
    "x = X.loc[:, features].values\n",
    "# Separating out the target\n",
    "# Standardizing the features\n",
    "x = StandardScaler().fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     principal component 1  principal component 2  principal component 3  \\\n",
      "0                -0.373309              -0.572159              -1.118644   \n",
      "1                -1.361744               0.328004              -2.023313   \n",
      "2                -1.684366              -2.465257               0.496397   \n",
      "3                -2.266613               1.710250              -2.410660   \n",
      "4                -3.887428              -1.739071               3.687272   \n",
      "..                     ...                    ...                    ...   \n",
      "995              -0.531507              -3.625279               0.099837   \n",
      "996              -0.379776              -3.891119               0.222217   \n",
      "997              -0.486179              -4.550413               1.918816   \n",
      "998              -2.210291              -1.093682              -0.936251   \n",
      "999              -1.049923              -2.211609              -1.551344   \n",
      "\n",
      "     principal component 4  principal component 5  principal component 6  \n",
      "0                 0.015864               0.143621              -0.009958  \n",
      "1                -0.517676              -0.635374              -1.234356  \n",
      "2                -0.332613              -0.835871              -0.079870  \n",
      "3                -1.192083              -0.701875               0.257736  \n",
      "4                 0.889632               1.245448               3.208146  \n",
      "..                     ...                    ...                    ...  \n",
      "995              -0.525113              -0.015873               0.269381  \n",
      "996              -0.216495               0.951855               0.748912  \n",
      "997              -0.344370               0.742436              -0.058277  \n",
      "998              -1.342302              -0.609395              -0.884015  \n",
      "999              -0.065629              -0.709513              -2.345759  \n",
      "\n",
      "[1000 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# pca = PCA(n_components=2)\n",
    "# principalComponents = pca.fit_transform(x)\n",
    "# principalDf = pd.DataFrame(data = principalComponents\n",
    "#              , columns = ['principal component 1', 'principal component 2'])\n",
    "# print(principalDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     principal component 1  principal component 2  principal component 3  \\\n",
      "0                -0.373309              -0.572159              -1.118644   \n",
      "1                -1.361744               0.328004              -2.023313   \n",
      "2                -1.684366              -2.465257               0.496397   \n",
      "3                -2.266613               1.710250              -2.410660   \n",
      "4                -3.887428              -1.739071               3.687272   \n",
      "..                     ...                    ...                    ...   \n",
      "995              -0.531507              -3.625279               0.099837   \n",
      "996              -0.379776              -3.891119               0.222217   \n",
      "997              -0.486179              -4.550413               1.918816   \n",
      "998              -2.210291              -1.093682              -0.936251   \n",
      "999              -1.049923              -2.211609              -1.551344   \n",
      "\n",
      "     principal component 4  principal component 5  principal component 6  \\\n",
      "0                 0.015864               0.143621              -0.009958   \n",
      "1                -0.517676              -0.635374              -1.234356   \n",
      "2                -0.332613              -0.835871              -0.079870   \n",
      "3                -1.192083              -0.701875               0.257736   \n",
      "4                 0.889632               1.245448               3.208146   \n",
      "..                     ...                    ...                    ...   \n",
      "995              -0.525113              -0.015873               0.269381   \n",
      "996              -0.216495               0.951855               0.748912   \n",
      "997              -0.344370               0.742436              -0.058277   \n",
      "998              -1.342302              -0.609395              -0.884015   \n",
      "999              -0.065629              -0.709513              -2.345759   \n",
      "\n",
      "     numlabels  \n",
      "0            0  \n",
      "1            0  \n",
      "2            0  \n",
      "3            0  \n",
      "4            0  \n",
      "..         ...  \n",
      "995          9  \n",
      "996          9  \n",
      "997          9  \n",
      "998          9  \n",
      "999          9  \n",
      "\n",
      "[1000 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# finalDf = pd.concat([principalDf, X[['numlabels']]], axis = 1)\n",
    "# print(finalDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = finalDf.drop(['numlabels'],axis=1)\n",
    "# #Y = finalDf.drop(['principal component 1', 'principal component 2'],axis=1)\n",
    "# X = np.array(X)\n",
    "# Y = np.array(finalDf['numlabels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape :  (900, 6) (900,)\n",
      "Testing data shape :  (100, 6) (100,)\n"
     ]
    }
   ],
   "source": [
    "print('Training data shape : ', X_train.shape, Y_train.shape)\n",
    "\n",
    "print('Testing data shape : ', X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((900, 6, 1, 1), (100, 6, 1, 1), (900,), (100,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train = X_train.reshape(900, 2, 1, 1)\n",
    "# X_test = X_test.reshape(100, 2, 1, 1)\n",
    "# X_train.shape, X_test.shape, Y_train.shape, Y_test.shape\n",
    "\n",
    "X_train = X_train.reshape(900, 6, 1, 1)\n",
    "X_test = X_test.reshape(100, 6, 1, 1)\n",
    "X_train.shape, X_test.shape, Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of outputs :  10\n",
      "Output classes :  [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "# Find the unique numbers from the train labels\n",
    "classes = np.unique(Y_train)\n",
    "nClasses = len(classes)\n",
    "print('Total number of outputs : ', nClasses)\n",
    "print('Output classes : ', classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape :  (900, 6, 1, 1) (900,)\n",
      "Testing data shape :  (100, 6, 1, 1) (100,)\n"
     ]
    }
   ],
   "source": [
    "print('Training data shape : ', X_train.shape, Y_train.shape)\n",
    "\n",
    "print('Testing data shape : ', X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original label: 5\n",
      "After conversion to one-hot: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Change the labels from categorical to one-hot encoding\n",
    "train_Y_one_hot = to_categorical(Y_train)\n",
    "test_Y_one_hot = to_categorical(Y_test)\n",
    "\n",
    "# Display the change for category label using one-hot encoding\n",
    "print('Original label:', Y_train[0])\n",
    "print('After conversion to one-hot:', train_Y_one_hot[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X,valid_X,train_label,valid_label = train_test_split(X_train, train_Y_one_hot, test_size=0.05, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((855, 6, 1, 1), (45, 6, 1, 1), (855, 10), (45, 10))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape,valid_X.shape,train_label.shape,valid_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense, Dropout, Flatten, InputLayer\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/45325802/valueerror-error-when-checking-input-expected-conv1d-1-input-to-have-3-dimensi\n",
    "batch_size = 128\n",
    "epochs = 1000\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_model = Sequential()\n",
    "music_model.add(Conv2D(32, kernel_size=(3, 3),activation='linear',input_shape=(6, 1, 1),padding='same'))\n",
    "music_model.add(LeakyReLU(alpha=0.1))\n",
    "music_model.add(MaxPooling2D((2, 2),padding='same'))\n",
    "music_model.add(Dropout(0.25))\n",
    "music_model.add(Conv2D(64, (3, 3), activation='linear',padding='same'))\n",
    "music_model.add(LeakyReLU(alpha=0.1))\n",
    "music_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "music_model.add(Dropout(0.25))\n",
    "music_model.add(Conv2D(128, (3, 3), activation='linear',padding='same'))\n",
    "music_model.add(LeakyReLU(alpha=0.1))                  \n",
    "music_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "music_model.add(Dropout(0.4))\n",
    "music_model.add(Flatten())\n",
    "music_model.add(Dense(128, activation='linear'))\n",
    "music_model.add(LeakyReLU(alpha=0.1))            \n",
    "music_model.add(Dropout(0.3))\n",
    "music_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "music_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
    "\n",
    "# music_model = Sequential()\n",
    "# music_model.add(Dense(10, input_dim=2, activation='relu'))\n",
    "# music_model.add(Dense(1, activation='relu'))\n",
    "# music_model.compile(loss = 'mean_squared_error', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 6, 1, 32)          320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 6, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 3, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 3, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 3, 1, 64)          18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 3, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 2, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 2, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 2, 1, 128)         73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)   (None, 2, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 110,474\n",
      "Trainable params: 110,474\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "music_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 855 samples, validate on 45 samples\n",
      "Epoch 1/1000\n",
      "855/855 [==============================] - 0s 268us/step - loss: 2.2975 - accuracy: 0.1158 - val_loss: 2.2805 - val_accuracy: 0.2889\n",
      "Epoch 2/1000\n",
      "855/855 [==============================] - 0s 46us/step - loss: 2.2791 - accuracy: 0.1965 - val_loss: 2.2438 - val_accuracy: 0.3556\n",
      "Epoch 3/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 2.2446 - accuracy: 0.2386 - val_loss: 2.1457 - val_accuracy: 0.4000\n",
      "Epoch 4/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 2.1826 - accuracy: 0.2444 - val_loss: 1.9851 - val_accuracy: 0.4667\n",
      "Epoch 5/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 2.0729 - accuracy: 0.2877 - val_loss: 1.8307 - val_accuracy: 0.4667\n",
      "Epoch 6/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 1.9667 - accuracy: 0.3263 - val_loss: 1.7078 - val_accuracy: 0.4667\n",
      "Epoch 7/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 1.8488 - accuracy: 0.3415 - val_loss: 1.5918 - val_accuracy: 0.4444\n",
      "Epoch 8/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 1.7926 - accuracy: 0.3404 - val_loss: 1.5133 - val_accuracy: 0.4222\n",
      "Epoch 9/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 1.7293 - accuracy: 0.3579 - val_loss: 1.4810 - val_accuracy: 0.4222\n",
      "Epoch 10/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 1.6858 - accuracy: 0.3766 - val_loss: 1.4852 - val_accuracy: 0.4222\n",
      "Epoch 11/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 1.6470 - accuracy: 0.3801 - val_loss: 1.4900 - val_accuracy: 0.4444\n",
      "Epoch 12/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 1.6235 - accuracy: 0.4070 - val_loss: 1.4815 - val_accuracy: 0.4444\n",
      "Epoch 13/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 1.5936 - accuracy: 0.4175 - val_loss: 1.4632 - val_accuracy: 0.4444\n",
      "Epoch 14/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 1.5805 - accuracy: 0.4058 - val_loss: 1.4386 - val_accuracy: 0.4222\n",
      "Epoch 15/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 1.5431 - accuracy: 0.4269 - val_loss: 1.4416 - val_accuracy: 0.4222\n",
      "Epoch 16/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 1.5388 - accuracy: 0.4269 - val_loss: 1.4419 - val_accuracy: 0.4222\n",
      "Epoch 17/1000\n",
      "855/855 [==============================] - 0s 49us/step - loss: 1.5316 - accuracy: 0.4398 - val_loss: 1.4251 - val_accuracy: 0.4222\n",
      "Epoch 18/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 1.5423 - accuracy: 0.4316 - val_loss: 1.4151 - val_accuracy: 0.4667\n",
      "Epoch 19/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 1.4897 - accuracy: 0.4526 - val_loss: 1.4465 - val_accuracy: 0.4000\n",
      "Epoch 20/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 1.4579 - accuracy: 0.4515 - val_loss: 1.4308 - val_accuracy: 0.4222\n",
      "Epoch 21/1000\n",
      "855/855 [==============================] - 0s 49us/step - loss: 1.4880 - accuracy: 0.4632 - val_loss: 1.4267 - val_accuracy: 0.4889\n",
      "Epoch 22/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 1.4836 - accuracy: 0.4292 - val_loss: 1.4332 - val_accuracy: 0.4444\n",
      "Epoch 23/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 1.4441 - accuracy: 0.4702 - val_loss: 1.4313 - val_accuracy: 0.4444\n",
      "Epoch 24/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 1.4633 - accuracy: 0.4596 - val_loss: 1.4378 - val_accuracy: 0.4444\n",
      "Epoch 25/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 1.4483 - accuracy: 0.4749 - val_loss: 1.3991 - val_accuracy: 0.4667\n",
      "Epoch 26/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 1.4639 - accuracy: 0.4702 - val_loss: 1.3934 - val_accuracy: 0.4667\n",
      "Epoch 27/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 1.4674 - accuracy: 0.4678 - val_loss: 1.4147 - val_accuracy: 0.4667\n",
      "Epoch 28/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 1.4344 - accuracy: 0.4807 - val_loss: 1.3891 - val_accuracy: 0.4667\n",
      "Epoch 29/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 1.4137 - accuracy: 0.4760 - val_loss: 1.3870 - val_accuracy: 0.4667\n",
      "Epoch 30/1000\n",
      "855/855 [==============================] - 0s 55us/step - loss: 1.4132 - accuracy: 0.4702 - val_loss: 1.3856 - val_accuracy: 0.4667\n",
      "Epoch 31/1000\n",
      "855/855 [==============================] - 0s 50us/step - loss: 1.3779 - accuracy: 0.5006 - val_loss: 1.3839 - val_accuracy: 0.4667\n",
      "Epoch 32/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 1.3971 - accuracy: 0.5029 - val_loss: 1.3868 - val_accuracy: 0.4667\n",
      "Epoch 33/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 1.3783 - accuracy: 0.4819 - val_loss: 1.4065 - val_accuracy: 0.4667\n",
      "Epoch 34/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 1.3698 - accuracy: 0.4947 - val_loss: 1.4126 - val_accuracy: 0.4667\n",
      "Epoch 35/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 1.3839 - accuracy: 0.4982 - val_loss: 1.3890 - val_accuracy: 0.4667\n",
      "Epoch 36/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 1.3583 - accuracy: 0.5041 - val_loss: 1.4202 - val_accuracy: 0.4889\n",
      "Epoch 37/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 1.3928 - accuracy: 0.4877 - val_loss: 1.3929 - val_accuracy: 0.4889\n",
      "Epoch 38/1000\n",
      "855/855 [==============================] - 0s 50us/step - loss: 1.3830 - accuracy: 0.4877 - val_loss: 1.3578 - val_accuracy: 0.4667\n",
      "Epoch 39/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 1.3715 - accuracy: 0.4807 - val_loss: 1.3663 - val_accuracy: 0.4889\n",
      "Epoch 40/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 1.3327 - accuracy: 0.5076 - val_loss: 1.3625 - val_accuracy: 0.4889\n",
      "Epoch 41/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 1.3577 - accuracy: 0.4924 - val_loss: 1.3362 - val_accuracy: 0.4889\n",
      "Epoch 42/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 1.3315 - accuracy: 0.5053 - val_loss: 1.3293 - val_accuracy: 0.4889\n",
      "Epoch 43/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 1.3319 - accuracy: 0.5064 - val_loss: 1.3895 - val_accuracy: 0.5111\n",
      "Epoch 44/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 1.3233 - accuracy: 0.5193 - val_loss: 1.3733 - val_accuracy: 0.5111\n",
      "Epoch 45/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 1.3107 - accuracy: 0.5170 - val_loss: 1.3543 - val_accuracy: 0.5111\n",
      "Epoch 46/1000\n",
      "855/855 [==============================] - 0s 55us/step - loss: 1.3533 - accuracy: 0.5099 - val_loss: 1.3607 - val_accuracy: 0.5111\n",
      "Epoch 47/1000\n",
      "855/855 [==============================] - 0s 51us/step - loss: 1.3315 - accuracy: 0.5099 - val_loss: 1.3390 - val_accuracy: 0.4889\n",
      "Epoch 48/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 1.3142 - accuracy: 0.5170 - val_loss: 1.3702 - val_accuracy: 0.5111\n",
      "Epoch 49/1000\n",
      "855/855 [==============================] - 0s 55us/step - loss: 1.3081 - accuracy: 0.5263 - val_loss: 1.3892 - val_accuracy: 0.5111\n",
      "Epoch 50/1000\n",
      "855/855 [==============================] - 0s 50us/step - loss: 1.2986 - accuracy: 0.5216 - val_loss: 1.3728 - val_accuracy: 0.5111\n",
      "Epoch 51/1000\n",
      "855/855 [==============================] - 0s 50us/step - loss: 1.3069 - accuracy: 0.5193 - val_loss: 1.3808 - val_accuracy: 0.4889\n",
      "Epoch 52/1000\n",
      "855/855 [==============================] - 0s 49us/step - loss: 1.3069 - accuracy: 0.5099 - val_loss: 1.3891 - val_accuracy: 0.5111\n",
      "Epoch 53/1000\n",
      "855/855 [==============================] - 0s 52us/step - loss: 1.2954 - accuracy: 0.5181 - val_loss: 1.3501 - val_accuracy: 0.4889\n",
      "Epoch 54/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 1.2784 - accuracy: 0.5111 - val_loss: 1.3225 - val_accuracy: 0.5111\n",
      "Epoch 55/1000\n",
      "855/855 [==============================] - 0s 46us/step - loss: 1.3033 - accuracy: 0.5251 - val_loss: 1.3494 - val_accuracy: 0.5111\n",
      "Epoch 56/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 1.3128 - accuracy: 0.5076 - val_loss: 1.3692 - val_accuracy: 0.5111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "855/855 [==============================] - 0s 52us/step - loss: 1.2859 - accuracy: 0.5181 - val_loss: 1.3957 - val_accuracy: 0.5111\n",
      "Epoch 58/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 1.2696 - accuracy: 0.5263 - val_loss: 1.4136 - val_accuracy: 0.4889\n",
      "Epoch 59/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 1.2806 - accuracy: 0.5263 - val_loss: 1.4269 - val_accuracy: 0.4889\n",
      "Epoch 60/1000\n",
      "855/855 [==============================] - 0s 49us/step - loss: 1.2948 - accuracy: 0.5322 - val_loss: 1.3798 - val_accuracy: 0.4667\n",
      "Epoch 61/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 1.2576 - accuracy: 0.5333 - val_loss: 1.3742 - val_accuracy: 0.5111\n",
      "Epoch 62/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 1.2840 - accuracy: 0.5251 - val_loss: 1.3572 - val_accuracy: 0.5111\n",
      "Epoch 63/1000\n",
      "855/855 [==============================] - 0s 50us/step - loss: 1.2467 - accuracy: 0.5637 - val_loss: 1.3650 - val_accuracy: 0.4889\n",
      "Epoch 64/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 1.2810 - accuracy: 0.5415 - val_loss: 1.3694 - val_accuracy: 0.4889\n",
      "Epoch 65/1000\n",
      "855/855 [==============================] - 0s 49us/step - loss: 1.2778 - accuracy: 0.5287 - val_loss: 1.3787 - val_accuracy: 0.5111\n",
      "Epoch 66/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 1.2593 - accuracy: 0.5392 - val_loss: 1.3986 - val_accuracy: 0.5111\n",
      "Epoch 67/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 1.2475 - accuracy: 0.5333 - val_loss: 1.4157 - val_accuracy: 0.5111\n",
      "Epoch 68/1000\n",
      "855/855 [==============================] - 0s 61us/step - loss: 1.2815 - accuracy: 0.5228 - val_loss: 1.3543 - val_accuracy: 0.5111\n",
      "Epoch 69/1000\n",
      "855/855 [==============================] - 0s 51us/step - loss: 1.2229 - accuracy: 0.5439 - val_loss: 1.3534 - val_accuracy: 0.5111\n",
      "Epoch 70/1000\n",
      "855/855 [==============================] - 0s 50us/step - loss: 1.2162 - accuracy: 0.5556 - val_loss: 1.3912 - val_accuracy: 0.5111\n",
      "Epoch 71/1000\n",
      "855/855 [==============================] - 0s 52us/step - loss: 1.2527 - accuracy: 0.5310 - val_loss: 1.3795 - val_accuracy: 0.5111\n",
      "Epoch 72/1000\n",
      "855/855 [==============================] - 0s 50us/step - loss: 1.2036 - accuracy: 0.5497 - val_loss: 1.3756 - val_accuracy: 0.5111\n",
      "Epoch 73/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 1.2389 - accuracy: 0.5392 - val_loss: 1.3839 - val_accuracy: 0.5111\n",
      "Epoch 74/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 1.2468 - accuracy: 0.5380 - val_loss: 1.3687 - val_accuracy: 0.5111\n",
      "Epoch 75/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 1.2414 - accuracy: 0.5287 - val_loss: 1.3413 - val_accuracy: 0.5111\n",
      "Epoch 76/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 1.2505 - accuracy: 0.5474 - val_loss: 1.3449 - val_accuracy: 0.5111\n",
      "Epoch 77/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 1.2685 - accuracy: 0.5404 - val_loss: 1.3507 - val_accuracy: 0.4889\n",
      "Epoch 78/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 1.2108 - accuracy: 0.5637 - val_loss: 1.3245 - val_accuracy: 0.5111\n",
      "Epoch 79/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 1.2003 - accuracy: 0.5673 - val_loss: 1.3631 - val_accuracy: 0.5111\n",
      "Epoch 80/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 1.2135 - accuracy: 0.5392 - val_loss: 1.4052 - val_accuracy: 0.5111\n",
      "Epoch 81/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 1.2127 - accuracy: 0.5392 - val_loss: 1.3872 - val_accuracy: 0.4889\n",
      "Epoch 82/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 1.1850 - accuracy: 0.5743 - val_loss: 1.3993 - val_accuracy: 0.5111\n",
      "Epoch 83/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 1.1755 - accuracy: 0.5766 - val_loss: 1.4213 - val_accuracy: 0.4889\n",
      "Epoch 84/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 1.2210 - accuracy: 0.5485 - val_loss: 1.3912 - val_accuracy: 0.5111\n",
      "Epoch 85/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 1.1834 - accuracy: 0.5661 - val_loss: 1.4048 - val_accuracy: 0.5111\n",
      "Epoch 86/1000\n",
      "855/855 [==============================] - 0s 42us/step - loss: 1.1863 - accuracy: 0.5474 - val_loss: 1.4188 - val_accuracy: 0.5111\n",
      "Epoch 87/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 1.2051 - accuracy: 0.5649 - val_loss: 1.3923 - val_accuracy: 0.5111\n",
      "Epoch 88/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 1.2080 - accuracy: 0.5637 - val_loss: 1.4044 - val_accuracy: 0.5111\n",
      "Epoch 89/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 1.1769 - accuracy: 0.5626 - val_loss: 1.4038 - val_accuracy: 0.5111\n",
      "Epoch 90/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 1.2215 - accuracy: 0.5415 - val_loss: 1.3822 - val_accuracy: 0.5111\n",
      "Epoch 91/1000\n",
      "855/855 [==============================] - 0s 49us/step - loss: 1.2104 - accuracy: 0.5474 - val_loss: 1.3989 - val_accuracy: 0.5111\n",
      "Epoch 92/1000\n",
      "855/855 [==============================] - 0s 50us/step - loss: 1.2167 - accuracy: 0.5614 - val_loss: 1.4380 - val_accuracy: 0.5111\n",
      "Epoch 93/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 1.1985 - accuracy: 0.5404 - val_loss: 1.3893 - val_accuracy: 0.5111\n",
      "Epoch 94/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 1.1792 - accuracy: 0.5591 - val_loss: 1.3724 - val_accuracy: 0.4889\n",
      "Epoch 95/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 1.1980 - accuracy: 0.5497 - val_loss: 1.3867 - val_accuracy: 0.5111\n",
      "Epoch 96/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 1.1583 - accuracy: 0.5649 - val_loss: 1.3983 - val_accuracy: 0.4889\n",
      "Epoch 97/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 1.1515 - accuracy: 0.5813 - val_loss: 1.4072 - val_accuracy: 0.4889\n",
      "Epoch 98/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 1.1408 - accuracy: 0.5825 - val_loss: 1.4089 - val_accuracy: 0.5111\n",
      "Epoch 99/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 1.1902 - accuracy: 0.5731 - val_loss: 1.4022 - val_accuracy: 0.5111\n",
      "Epoch 100/1000\n",
      "855/855 [==============================] - 0s 50us/step - loss: 1.1623 - accuracy: 0.5731 - val_loss: 1.4072 - val_accuracy: 0.4889\n",
      "Epoch 101/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 1.1707 - accuracy: 0.5953 - val_loss: 1.4212 - val_accuracy: 0.5111\n",
      "Epoch 102/1000\n",
      "855/855 [==============================] - 0s 49us/step - loss: 1.1525 - accuracy: 0.5801 - val_loss: 1.4166 - val_accuracy: 0.5111\n",
      "Epoch 103/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 1.1461 - accuracy: 0.5731 - val_loss: 1.3731 - val_accuracy: 0.5111\n",
      "Epoch 104/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 1.1587 - accuracy: 0.5743 - val_loss: 1.3608 - val_accuracy: 0.5111\n",
      "Epoch 105/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 1.1264 - accuracy: 0.5988 - val_loss: 1.3471 - val_accuracy: 0.5111\n",
      "Epoch 106/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 1.1374 - accuracy: 0.5743 - val_loss: 1.3503 - val_accuracy: 0.4889\n",
      "Epoch 107/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 1.1629 - accuracy: 0.5743 - val_loss: 1.3964 - val_accuracy: 0.4889\n",
      "Epoch 108/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 1.1098 - accuracy: 0.5754 - val_loss: 1.3784 - val_accuracy: 0.4889\n",
      "Epoch 109/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 1.1384 - accuracy: 0.5953 - val_loss: 1.3957 - val_accuracy: 0.4889\n",
      "Epoch 110/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 1.1398 - accuracy: 0.5696 - val_loss: 1.4191 - val_accuracy: 0.5111\n",
      "Epoch 111/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 1.1361 - accuracy: 0.5673 - val_loss: 1.4212 - val_accuracy: 0.5111\n",
      "Epoch 112/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 1.1413 - accuracy: 0.5789 - val_loss: 1.4204 - val_accuracy: 0.5111\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "855/855 [==============================] - 0s 44us/step - loss: 1.0922 - accuracy: 0.5801 - val_loss: 1.4360 - val_accuracy: 0.5111\n",
      "Epoch 114/1000\n",
      "855/855 [==============================] - 0s 51us/step - loss: 1.1381 - accuracy: 0.5544 - val_loss: 1.4134 - val_accuracy: 0.5111\n",
      "Epoch 115/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 1.1072 - accuracy: 0.5918 - val_loss: 1.3905 - val_accuracy: 0.4889\n",
      "Epoch 116/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 1.1156 - accuracy: 0.5965 - val_loss: 1.4208 - val_accuracy: 0.4889\n",
      "Epoch 117/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 1.1221 - accuracy: 0.5965 - val_loss: 1.4127 - val_accuracy: 0.5111\n",
      "Epoch 118/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 1.1151 - accuracy: 0.5778 - val_loss: 1.3913 - val_accuracy: 0.4889\n",
      "Epoch 119/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 1.1180 - accuracy: 0.5883 - val_loss: 1.3884 - val_accuracy: 0.4889\n",
      "Epoch 120/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 1.0928 - accuracy: 0.6058 - val_loss: 1.4027 - val_accuracy: 0.4889\n",
      "Epoch 121/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 1.1214 - accuracy: 0.5871 - val_loss: 1.4375 - val_accuracy: 0.4889\n",
      "Epoch 122/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 1.1404 - accuracy: 0.5696 - val_loss: 1.5004 - val_accuracy: 0.5111\n",
      "Epoch 123/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 1.1695 - accuracy: 0.5754 - val_loss: 1.4676 - val_accuracy: 0.5111\n",
      "Epoch 124/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 1.1070 - accuracy: 0.5825 - val_loss: 1.4005 - val_accuracy: 0.5111\n",
      "Epoch 125/1000\n",
      "855/855 [==============================] - 0s 50us/step - loss: 1.1047 - accuracy: 0.5883 - val_loss: 1.3711 - val_accuracy: 0.5111\n",
      "Epoch 126/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 1.1299 - accuracy: 0.5953 - val_loss: 1.4063 - val_accuracy: 0.4889\n",
      "Epoch 127/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 1.1048 - accuracy: 0.5977 - val_loss: 1.4292 - val_accuracy: 0.4889\n",
      "Epoch 128/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 1.0771 - accuracy: 0.6047 - val_loss: 1.4202 - val_accuracy: 0.4889\n",
      "Epoch 129/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 1.1096 - accuracy: 0.5871 - val_loss: 1.4144 - val_accuracy: 0.4889\n",
      "Epoch 130/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 1.1028 - accuracy: 0.5860 - val_loss: 1.3892 - val_accuracy: 0.4889\n",
      "Epoch 131/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 1.1045 - accuracy: 0.6047 - val_loss: 1.4321 - val_accuracy: 0.4889\n",
      "Epoch 132/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 1.1090 - accuracy: 0.5813 - val_loss: 1.4644 - val_accuracy: 0.4889\n",
      "Epoch 133/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 1.0695 - accuracy: 0.6070 - val_loss: 1.4722 - val_accuracy: 0.4889\n",
      "Epoch 134/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 1.0814 - accuracy: 0.5988 - val_loss: 1.4827 - val_accuracy: 0.4889\n",
      "Epoch 135/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 1.0839 - accuracy: 0.5988 - val_loss: 1.4614 - val_accuracy: 0.5111\n",
      "Epoch 136/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 1.0782 - accuracy: 0.5836 - val_loss: 1.4292 - val_accuracy: 0.5111\n",
      "Epoch 137/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 1.0897 - accuracy: 0.6105 - val_loss: 1.4631 - val_accuracy: 0.4889\n",
      "Epoch 138/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 1.0317 - accuracy: 0.6211 - val_loss: 1.4781 - val_accuracy: 0.4667\n",
      "Epoch 139/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 1.0573 - accuracy: 0.6152 - val_loss: 1.4589 - val_accuracy: 0.4889\n",
      "Epoch 140/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 1.0839 - accuracy: 0.6246 - val_loss: 1.4581 - val_accuracy: 0.4889\n",
      "Epoch 141/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 1.0792 - accuracy: 0.6012 - val_loss: 1.4751 - val_accuracy: 0.4889\n",
      "Epoch 142/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 1.1148 - accuracy: 0.5906 - val_loss: 1.4959 - val_accuracy: 0.5111\n",
      "Epoch 143/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 1.0669 - accuracy: 0.6175 - val_loss: 1.4841 - val_accuracy: 0.5111\n",
      "Epoch 144/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 1.0633 - accuracy: 0.6023 - val_loss: 1.5203 - val_accuracy: 0.5111\n",
      "Epoch 145/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 1.0609 - accuracy: 0.6012 - val_loss: 1.5100 - val_accuracy: 0.4889\n",
      "Epoch 146/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 1.0457 - accuracy: 0.6211 - val_loss: 1.4808 - val_accuracy: 0.4667\n",
      "Epoch 147/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 1.0538 - accuracy: 0.6094 - val_loss: 1.4801 - val_accuracy: 0.4889\n",
      "Epoch 148/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 1.0744 - accuracy: 0.5942 - val_loss: 1.4946 - val_accuracy: 0.4889\n",
      "Epoch 149/1000\n",
      "855/855 [==============================] - 0s 46us/step - loss: 1.0889 - accuracy: 0.5930 - val_loss: 1.4701 - val_accuracy: 0.5111\n",
      "Epoch 150/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 1.0582 - accuracy: 0.6105 - val_loss: 1.4828 - val_accuracy: 0.4889\n",
      "Epoch 151/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 1.0737 - accuracy: 0.6070 - val_loss: 1.4901 - val_accuracy: 0.4889\n",
      "Epoch 152/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 1.0541 - accuracy: 0.5965 - val_loss: 1.4867 - val_accuracy: 0.4667\n",
      "Epoch 153/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 1.0477 - accuracy: 0.6058 - val_loss: 1.4932 - val_accuracy: 0.4667\n",
      "Epoch 154/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 1.0787 - accuracy: 0.6047 - val_loss: 1.4738 - val_accuracy: 0.4889\n",
      "Epoch 155/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 1.0206 - accuracy: 0.6222 - val_loss: 1.4636 - val_accuracy: 0.4889\n",
      "Epoch 156/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 1.0604 - accuracy: 0.6246 - val_loss: 1.4760 - val_accuracy: 0.4889\n",
      "Epoch 157/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 1.0628 - accuracy: 0.6164 - val_loss: 1.5185 - val_accuracy: 0.4889\n",
      "Epoch 158/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 1.0380 - accuracy: 0.6175 - val_loss: 1.5238 - val_accuracy: 0.4889\n",
      "Epoch 159/1000\n",
      "855/855 [==============================] - 0s 42us/step - loss: 1.0521 - accuracy: 0.6199 - val_loss: 1.5194 - val_accuracy: 0.4889\n",
      "Epoch 160/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 1.0789 - accuracy: 0.5906 - val_loss: 1.5179 - val_accuracy: 0.4889\n",
      "Epoch 161/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 1.0411 - accuracy: 0.6140 - val_loss: 1.5378 - val_accuracy: 0.4889\n",
      "Epoch 162/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 1.0561 - accuracy: 0.5906 - val_loss: 1.5534 - val_accuracy: 0.4889\n",
      "Epoch 163/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 1.0565 - accuracy: 0.5825 - val_loss: 1.5346 - val_accuracy: 0.4667\n",
      "Epoch 164/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 1.0164 - accuracy: 0.6105 - val_loss: 1.5081 - val_accuracy: 0.4889\n",
      "Epoch 165/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 1.0441 - accuracy: 0.6012 - val_loss: 1.5036 - val_accuracy: 0.4889\n",
      "Epoch 166/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 1.0032 - accuracy: 0.6292 - val_loss: 1.4948 - val_accuracy: 0.4889\n",
      "Epoch 167/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 1.0552 - accuracy: 0.6070 - val_loss: 1.4734 - val_accuracy: 0.4667\n",
      "Epoch 168/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 1.0324 - accuracy: 0.6035 - val_loss: 1.5104 - val_accuracy: 0.4667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 1.0308 - accuracy: 0.6257 - val_loss: 1.5255 - val_accuracy: 0.4889\n",
      "Epoch 170/1000\n",
      "855/855 [==============================] - 0s 42us/step - loss: 1.0339 - accuracy: 0.6105 - val_loss: 1.4930 - val_accuracy: 0.4889\n",
      "Epoch 171/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 1.0359 - accuracy: 0.6140 - val_loss: 1.4845 - val_accuracy: 0.4889\n",
      "Epoch 172/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.9949 - accuracy: 0.6316 - val_loss: 1.4930 - val_accuracy: 0.4889\n",
      "Epoch 173/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.9965 - accuracy: 0.6386 - val_loss: 1.4891 - val_accuracy: 0.4889\n",
      "Epoch 174/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 1.0047 - accuracy: 0.6561 - val_loss: 1.5098 - val_accuracy: 0.4889\n",
      "Epoch 175/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 1.0259 - accuracy: 0.6327 - val_loss: 1.5526 - val_accuracy: 0.4889\n",
      "Epoch 176/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 1.0383 - accuracy: 0.6211 - val_loss: 1.5472 - val_accuracy: 0.4889\n",
      "Epoch 177/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 1.0280 - accuracy: 0.6246 - val_loss: 1.5156 - val_accuracy: 0.4889\n",
      "Epoch 178/1000\n",
      "855/855 [==============================] - 0s 42us/step - loss: 1.0099 - accuracy: 0.6316 - val_loss: 1.4935 - val_accuracy: 0.4889\n",
      "Epoch 179/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.9806 - accuracy: 0.6351 - val_loss: 1.5067 - val_accuracy: 0.4667\n",
      "Epoch 180/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 1.0076 - accuracy: 0.6234 - val_loss: 1.5308 - val_accuracy: 0.4889\n",
      "Epoch 181/1000\n",
      "855/855 [==============================] - 0s 42us/step - loss: 0.9870 - accuracy: 0.6374 - val_loss: 1.5601 - val_accuracy: 0.4889\n",
      "Epoch 182/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.9853 - accuracy: 0.5942 - val_loss: 1.5597 - val_accuracy: 0.4889\n",
      "Epoch 183/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.9834 - accuracy: 0.6316 - val_loss: 1.5375 - val_accuracy: 0.4889\n",
      "Epoch 184/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.9818 - accuracy: 0.6363 - val_loss: 1.5391 - val_accuracy: 0.4889\n",
      "Epoch 185/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 1.0055 - accuracy: 0.6304 - val_loss: 1.5254 - val_accuracy: 0.4889\n",
      "Epoch 186/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 1.0346 - accuracy: 0.6152 - val_loss: 1.5140 - val_accuracy: 0.4889\n",
      "Epoch 187/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.9656 - accuracy: 0.6316 - val_loss: 1.5301 - val_accuracy: 0.4889\n",
      "Epoch 188/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.9838 - accuracy: 0.6246 - val_loss: 1.4993 - val_accuracy: 0.4889\n",
      "Epoch 189/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.9800 - accuracy: 0.6292 - val_loss: 1.5115 - val_accuracy: 0.4889\n",
      "Epoch 190/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.9728 - accuracy: 0.6409 - val_loss: 1.5265 - val_accuracy: 0.4889\n",
      "Epoch 191/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.9674 - accuracy: 0.6468 - val_loss: 1.5435 - val_accuracy: 0.4889\n",
      "Epoch 192/1000\n",
      "855/855 [==============================] - 0s 46us/step - loss: 1.0111 - accuracy: 0.6129 - val_loss: 1.5416 - val_accuracy: 0.4889\n",
      "Epoch 193/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 1.0049 - accuracy: 0.6269 - val_loss: 1.4958 - val_accuracy: 0.4889\n",
      "Epoch 194/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.9726 - accuracy: 0.6374 - val_loss: 1.4829 - val_accuracy: 0.4889\n",
      "Epoch 195/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 1.0190 - accuracy: 0.6175 - val_loss: 1.5272 - val_accuracy: 0.4889\n",
      "Epoch 196/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.9978 - accuracy: 0.6316 - val_loss: 1.5098 - val_accuracy: 0.4667\n",
      "Epoch 197/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.9884 - accuracy: 0.6269 - val_loss: 1.4894 - val_accuracy: 0.4667\n",
      "Epoch 198/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.9818 - accuracy: 0.6257 - val_loss: 1.5142 - val_accuracy: 0.4889\n",
      "Epoch 199/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.9754 - accuracy: 0.6339 - val_loss: 1.5379 - val_accuracy: 0.4889\n",
      "Epoch 200/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.9475 - accuracy: 0.6374 - val_loss: 1.5667 - val_accuracy: 0.4667\n",
      "Epoch 201/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.9927 - accuracy: 0.6269 - val_loss: 1.6066 - val_accuracy: 0.4667\n",
      "Epoch 202/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.9720 - accuracy: 0.6398 - val_loss: 1.6488 - val_accuracy: 0.4889\n",
      "Epoch 203/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.9619 - accuracy: 0.6234 - val_loss: 1.6778 - val_accuracy: 0.4667\n",
      "Epoch 204/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 1.0083 - accuracy: 0.6094 - val_loss: 1.6683 - val_accuracy: 0.4889\n",
      "Epoch 205/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.9592 - accuracy: 0.6281 - val_loss: 1.6663 - val_accuracy: 0.4667\n",
      "Epoch 206/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.9595 - accuracy: 0.6456 - val_loss: 1.6278 - val_accuracy: 0.4667\n",
      "Epoch 207/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.9665 - accuracy: 0.6257 - val_loss: 1.5895 - val_accuracy: 0.4667\n",
      "Epoch 208/1000\n",
      "855/855 [==============================] - 0s 41us/step - loss: 0.9893 - accuracy: 0.6246 - val_loss: 1.5751 - val_accuracy: 0.4667\n",
      "Epoch 209/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.9572 - accuracy: 0.6550 - val_loss: 1.6106 - val_accuracy: 0.4889\n",
      "Epoch 210/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.9774 - accuracy: 0.6316 - val_loss: 1.6329 - val_accuracy: 0.4889\n",
      "Epoch 211/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.9713 - accuracy: 0.6409 - val_loss: 1.6259 - val_accuracy: 0.4889\n",
      "Epoch 212/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.9569 - accuracy: 0.6515 - val_loss: 1.5971 - val_accuracy: 0.4889\n",
      "Epoch 213/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.9209 - accuracy: 0.6550 - val_loss: 1.6120 - val_accuracy: 0.4889\n",
      "Epoch 214/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.9743 - accuracy: 0.6339 - val_loss: 1.5930 - val_accuracy: 0.4667\n",
      "Epoch 215/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.9452 - accuracy: 0.6608 - val_loss: 1.5930 - val_accuracy: 0.4667\n",
      "Epoch 216/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.9634 - accuracy: 0.6515 - val_loss: 1.6111 - val_accuracy: 0.4667\n",
      "Epoch 217/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.9489 - accuracy: 0.6257 - val_loss: 1.6312 - val_accuracy: 0.4667\n",
      "Epoch 218/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.9568 - accuracy: 0.6363 - val_loss: 1.6268 - val_accuracy: 0.4667\n",
      "Epoch 219/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.9103 - accuracy: 0.6444 - val_loss: 1.6269 - val_accuracy: 0.4889\n",
      "Epoch 220/1000\n",
      "855/855 [==============================] - 0s 42us/step - loss: 0.9451 - accuracy: 0.6538 - val_loss: 1.6395 - val_accuracy: 0.4889\n",
      "Epoch 221/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.9490 - accuracy: 0.6433 - val_loss: 1.6174 - val_accuracy: 0.4667\n",
      "Epoch 222/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.9735 - accuracy: 0.6199 - val_loss: 1.6206 - val_accuracy: 0.4667\n",
      "Epoch 223/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.9019 - accuracy: 0.6690 - val_loss: 1.6419 - val_accuracy: 0.4889\n",
      "Epoch 224/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 0.9446 - accuracy: 0.6561 - val_loss: 1.6274 - val_accuracy: 0.4889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.9428 - accuracy: 0.6573 - val_loss: 1.6136 - val_accuracy: 0.4889\n",
      "Epoch 226/1000\n",
      "855/855 [==============================] - 0s 46us/step - loss: 0.9299 - accuracy: 0.6667 - val_loss: 1.6323 - val_accuracy: 0.4667\n",
      "Epoch 227/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.9274 - accuracy: 0.6550 - val_loss: 1.6776 - val_accuracy: 0.4667\n",
      "Epoch 228/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.9232 - accuracy: 0.6398 - val_loss: 1.6882 - val_accuracy: 0.4667\n",
      "Epoch 229/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.9119 - accuracy: 0.6585 - val_loss: 1.6602 - val_accuracy: 0.4667\n",
      "Epoch 230/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.9350 - accuracy: 0.6503 - val_loss: 1.6500 - val_accuracy: 0.4667\n",
      "Epoch 231/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.9435 - accuracy: 0.6480 - val_loss: 1.6594 - val_accuracy: 0.4667\n",
      "Epoch 232/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.9357 - accuracy: 0.6515 - val_loss: 1.6566 - val_accuracy: 0.4667\n",
      "Epoch 233/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.9447 - accuracy: 0.6444 - val_loss: 1.6693 - val_accuracy: 0.4889\n",
      "Epoch 234/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.8896 - accuracy: 0.6830 - val_loss: 1.6927 - val_accuracy: 0.4889\n",
      "Epoch 235/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.9044 - accuracy: 0.6620 - val_loss: 1.7147 - val_accuracy: 0.4889\n",
      "Epoch 236/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.9385 - accuracy: 0.6468 - val_loss: 1.7092 - val_accuracy: 0.4667\n",
      "Epoch 237/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.9151 - accuracy: 0.6433 - val_loss: 1.6738 - val_accuracy: 0.4667\n",
      "Epoch 238/1000\n",
      "855/855 [==============================] - 0s 59us/step - loss: 0.9342 - accuracy: 0.6421 - val_loss: 1.6452 - val_accuracy: 0.4667\n",
      "Epoch 239/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.9207 - accuracy: 0.6772 - val_loss: 1.6528 - val_accuracy: 0.4667\n",
      "Epoch 240/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 0.9331 - accuracy: 0.6550 - val_loss: 1.6741 - val_accuracy: 0.4889\n",
      "Epoch 241/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.8965 - accuracy: 0.6667 - val_loss: 1.6505 - val_accuracy: 0.4667\n",
      "Epoch 242/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.9239 - accuracy: 0.6421 - val_loss: 1.5978 - val_accuracy: 0.4667\n",
      "Epoch 243/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.9221 - accuracy: 0.6620 - val_loss: 1.5714 - val_accuracy: 0.4667\n",
      "Epoch 244/1000\n",
      "855/855 [==============================] - 0s 42us/step - loss: 0.9246 - accuracy: 0.6444 - val_loss: 1.5996 - val_accuracy: 0.4667\n",
      "Epoch 245/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.9040 - accuracy: 0.6678 - val_loss: 1.6208 - val_accuracy: 0.4889\n",
      "Epoch 246/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.8662 - accuracy: 0.6690 - val_loss: 1.6290 - val_accuracy: 0.4667\n",
      "Epoch 247/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.9102 - accuracy: 0.6515 - val_loss: 1.6666 - val_accuracy: 0.4667\n",
      "Epoch 248/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.8910 - accuracy: 0.6596 - val_loss: 1.6876 - val_accuracy: 0.4667\n",
      "Epoch 249/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.8943 - accuracy: 0.6760 - val_loss: 1.7009 - val_accuracy: 0.4667\n",
      "Epoch 250/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.9018 - accuracy: 0.6538 - val_loss: 1.6803 - val_accuracy: 0.4667\n",
      "Epoch 251/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.9148 - accuracy: 0.6398 - val_loss: 1.6365 - val_accuracy: 0.4889\n",
      "Epoch 252/1000\n",
      "855/855 [==============================] - 0s 42us/step - loss: 0.9149 - accuracy: 0.6480 - val_loss: 1.6138 - val_accuracy: 0.4667\n",
      "Epoch 253/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.9151 - accuracy: 0.6550 - val_loss: 1.6589 - val_accuracy: 0.4667\n",
      "Epoch 254/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.8623 - accuracy: 0.6749 - val_loss: 1.7039 - val_accuracy: 0.4667\n",
      "Epoch 255/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.8658 - accuracy: 0.6784 - val_loss: 1.7330 - val_accuracy: 0.4667\n",
      "Epoch 256/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.8813 - accuracy: 0.6573 - val_loss: 1.7575 - val_accuracy: 0.4667\n",
      "Epoch 257/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.9067 - accuracy: 0.6678 - val_loss: 1.7727 - val_accuracy: 0.4667\n",
      "Epoch 258/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.9069 - accuracy: 0.6643 - val_loss: 1.7560 - val_accuracy: 0.4667\n",
      "Epoch 259/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.8869 - accuracy: 0.6655 - val_loss: 1.7366 - val_accuracy: 0.4444\n",
      "Epoch 260/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.9035 - accuracy: 0.6749 - val_loss: 1.7382 - val_accuracy: 0.4667\n",
      "Epoch 261/1000\n",
      "855/855 [==============================] - 0s 58us/step - loss: 0.8794 - accuracy: 0.6784 - val_loss: 1.7439 - val_accuracy: 0.4667\n",
      "Epoch 262/1000\n",
      "855/855 [==============================] - 0s 49us/step - loss: 0.8746 - accuracy: 0.6784 - val_loss: 1.7560 - val_accuracy: 0.4667\n",
      "Epoch 263/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.8960 - accuracy: 0.6760 - val_loss: 1.7588 - val_accuracy: 0.4889\n",
      "Epoch 264/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 0.8988 - accuracy: 0.6737 - val_loss: 1.7537 - val_accuracy: 0.4889\n",
      "Epoch 265/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.8746 - accuracy: 0.6620 - val_loss: 1.7600 - val_accuracy: 0.4667\n",
      "Epoch 266/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.8940 - accuracy: 0.6515 - val_loss: 1.7135 - val_accuracy: 0.4667\n",
      "Epoch 267/1000\n",
      "855/855 [==============================] - 0s 49us/step - loss: 0.8639 - accuracy: 0.6784 - val_loss: 1.6693 - val_accuracy: 0.4667\n",
      "Epoch 268/1000\n",
      "855/855 [==============================] - 0s 50us/step - loss: 0.8541 - accuracy: 0.6819 - val_loss: 1.6720 - val_accuracy: 0.4889\n",
      "Epoch 269/1000\n",
      "855/855 [==============================] - 0s 56us/step - loss: 0.8966 - accuracy: 0.6515 - val_loss: 1.6757 - val_accuracy: 0.4889\n",
      "Epoch 270/1000\n",
      "855/855 [==============================] - 0s 59us/step - loss: 0.8950 - accuracy: 0.6596 - val_loss: 1.6792 - val_accuracy: 0.4889\n",
      "Epoch 271/1000\n",
      "855/855 [==============================] - 0s 76us/step - loss: 0.8577 - accuracy: 0.6702 - val_loss: 1.7326 - val_accuracy: 0.4667\n",
      "Epoch 272/1000\n",
      "855/855 [==============================] - 0s 54us/step - loss: 0.8953 - accuracy: 0.6596 - val_loss: 1.7840 - val_accuracy: 0.4667\n",
      "Epoch 273/1000\n",
      "855/855 [==============================] - 0s 49us/step - loss: 0.9082 - accuracy: 0.6491 - val_loss: 1.7651 - val_accuracy: 0.4667\n",
      "Epoch 274/1000\n",
      "855/855 [==============================] - 0s 50us/step - loss: 0.8819 - accuracy: 0.6749 - val_loss: 1.7414 - val_accuracy: 0.4667\n",
      "Epoch 275/1000\n",
      "855/855 [==============================] - 0s 53us/step - loss: 0.8716 - accuracy: 0.6702 - val_loss: 1.7328 - val_accuracy: 0.4667\n",
      "Epoch 276/1000\n",
      "855/855 [==============================] - 0s 49us/step - loss: 0.8986 - accuracy: 0.6749 - val_loss: 1.7005 - val_accuracy: 0.4667\n",
      "Epoch 277/1000\n",
      "855/855 [==============================] - 0s 46us/step - loss: 0.8829 - accuracy: 0.6713 - val_loss: 1.7164 - val_accuracy: 0.4667\n",
      "Epoch 278/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 0.8769 - accuracy: 0.6538 - val_loss: 1.7431 - val_accuracy: 0.4444\n",
      "Epoch 279/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.8641 - accuracy: 0.6784 - val_loss: 1.8196 - val_accuracy: 0.4667\n",
      "Epoch 280/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.8473 - accuracy: 0.6795 - val_loss: 1.8275 - val_accuracy: 0.4667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.8917 - accuracy: 0.6620 - val_loss: 1.8030 - val_accuracy: 0.4889\n",
      "Epoch 282/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.8733 - accuracy: 0.6889 - val_loss: 1.7384 - val_accuracy: 0.4889\n",
      "Epoch 283/1000\n",
      "855/855 [==============================] - 0s 50us/step - loss: 0.8838 - accuracy: 0.6819 - val_loss: 1.7722 - val_accuracy: 0.4889\n",
      "Epoch 284/1000\n",
      "855/855 [==============================] - 0s 52us/step - loss: 0.8431 - accuracy: 0.6994 - val_loss: 1.7677 - val_accuracy: 0.4889\n",
      "Epoch 285/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 0.8825 - accuracy: 0.6784 - val_loss: 1.7476 - val_accuracy: 0.4889\n",
      "Epoch 286/1000\n",
      "855/855 [==============================] - 0s 49us/step - loss: 0.8312 - accuracy: 0.6784 - val_loss: 1.7514 - val_accuracy: 0.4889\n",
      "Epoch 287/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.8971 - accuracy: 0.6795 - val_loss: 1.7223 - val_accuracy: 0.4889\n",
      "Epoch 288/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.8589 - accuracy: 0.6854 - val_loss: 1.7009 - val_accuracy: 0.4667\n",
      "Epoch 289/1000\n",
      "855/855 [==============================] - 0s 42us/step - loss: 0.8200 - accuracy: 0.6947 - val_loss: 1.7051 - val_accuracy: 0.4667\n",
      "Epoch 290/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.9151 - accuracy: 0.6550 - val_loss: 1.7269 - val_accuracy: 0.4667\n",
      "Epoch 291/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.8595 - accuracy: 0.6725 - val_loss: 1.7432 - val_accuracy: 0.4889\n",
      "Epoch 292/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.8157 - accuracy: 0.6947 - val_loss: 1.7632 - val_accuracy: 0.4889\n",
      "Epoch 293/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.8492 - accuracy: 0.6795 - val_loss: 1.7588 - val_accuracy: 0.4889\n",
      "Epoch 294/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.8917 - accuracy: 0.6667 - val_loss: 1.7776 - val_accuracy: 0.4667\n",
      "Epoch 295/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.8378 - accuracy: 0.6936 - val_loss: 1.7353 - val_accuracy: 0.4889\n",
      "Epoch 296/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.8623 - accuracy: 0.6749 - val_loss: 1.6923 - val_accuracy: 0.4889\n",
      "Epoch 297/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.8852 - accuracy: 0.6608 - val_loss: 1.6930 - val_accuracy: 0.4889\n",
      "Epoch 298/1000\n",
      "855/855 [==============================] - 0s 42us/step - loss: 0.7979 - accuracy: 0.6877 - val_loss: 1.7465 - val_accuracy: 0.4889\n",
      "Epoch 299/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.8460 - accuracy: 0.6854 - val_loss: 1.7585 - val_accuracy: 0.4667\n",
      "Epoch 300/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.8700 - accuracy: 0.6795 - val_loss: 1.7210 - val_accuracy: 0.4667\n",
      "Epoch 301/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.8572 - accuracy: 0.6585 - val_loss: 1.7108 - val_accuracy: 0.4889\n",
      "Epoch 302/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.8555 - accuracy: 0.6667 - val_loss: 1.7129 - val_accuracy: 0.4667\n",
      "Epoch 303/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.8347 - accuracy: 0.6819 - val_loss: 1.7074 - val_accuracy: 0.4667\n",
      "Epoch 304/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.8836 - accuracy: 0.6538 - val_loss: 1.7210 - val_accuracy: 0.4667\n",
      "Epoch 305/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.8370 - accuracy: 0.6702 - val_loss: 1.6855 - val_accuracy: 0.4889\n",
      "Epoch 306/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.8469 - accuracy: 0.6807 - val_loss: 1.6595 - val_accuracy: 0.4667\n",
      "Epoch 307/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.8141 - accuracy: 0.6982 - val_loss: 1.7371 - val_accuracy: 0.4667\n",
      "Epoch 308/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.8734 - accuracy: 0.6608 - val_loss: 1.7433 - val_accuracy: 0.4667\n",
      "Epoch 309/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.8555 - accuracy: 0.6667 - val_loss: 1.7274 - val_accuracy: 0.4667\n",
      "Epoch 310/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.8410 - accuracy: 0.6795 - val_loss: 1.7291 - val_accuracy: 0.4444\n",
      "Epoch 311/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.8546 - accuracy: 0.6772 - val_loss: 1.7838 - val_accuracy: 0.4667\n",
      "Epoch 312/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.8245 - accuracy: 0.6784 - val_loss: 1.7538 - val_accuracy: 0.4667\n",
      "Epoch 313/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.8244 - accuracy: 0.6842 - val_loss: 1.7278 - val_accuracy: 0.4667\n",
      "Epoch 314/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.8441 - accuracy: 0.6865 - val_loss: 1.7156 - val_accuracy: 0.4667\n",
      "Epoch 315/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.8449 - accuracy: 0.6819 - val_loss: 1.7143 - val_accuracy: 0.4667\n",
      "Epoch 316/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.8309 - accuracy: 0.6842 - val_loss: 1.6865 - val_accuracy: 0.4667\n",
      "Epoch 317/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.8061 - accuracy: 0.6947 - val_loss: 1.7168 - val_accuracy: 0.4667\n",
      "Epoch 318/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.8064 - accuracy: 0.6936 - val_loss: 1.7642 - val_accuracy: 0.4667\n",
      "Epoch 319/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 0.8445 - accuracy: 0.6854 - val_loss: 1.7782 - val_accuracy: 0.4444\n",
      "Epoch 320/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.8203 - accuracy: 0.7006 - val_loss: 1.7743 - val_accuracy: 0.4444\n",
      "Epoch 321/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.8690 - accuracy: 0.6538 - val_loss: 1.7780 - val_accuracy: 0.4667\n",
      "Epoch 322/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.8753 - accuracy: 0.6760 - val_loss: 1.8105 - val_accuracy: 0.4889\n",
      "Epoch 323/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.8210 - accuracy: 0.6982 - val_loss: 1.7931 - val_accuracy: 0.4889\n",
      "Epoch 324/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.7785 - accuracy: 0.7029 - val_loss: 1.7632 - val_accuracy: 0.4667\n",
      "Epoch 325/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.8361 - accuracy: 0.6795 - val_loss: 1.7767 - val_accuracy: 0.4889\n",
      "Epoch 326/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.8188 - accuracy: 0.6795 - val_loss: 1.7406 - val_accuracy: 0.4889\n",
      "Epoch 327/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.8097 - accuracy: 0.6725 - val_loss: 1.7444 - val_accuracy: 0.4889\n",
      "Epoch 328/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.7956 - accuracy: 0.6889 - val_loss: 1.7951 - val_accuracy: 0.4889\n",
      "Epoch 329/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.8442 - accuracy: 0.6807 - val_loss: 1.7800 - val_accuracy: 0.4667\n",
      "Epoch 330/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.7858 - accuracy: 0.7041 - val_loss: 1.7505 - val_accuracy: 0.4444\n",
      "Epoch 331/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.7818 - accuracy: 0.6982 - val_loss: 1.7738 - val_accuracy: 0.4444\n",
      "Epoch 332/1000\n",
      "855/855 [==============================] - 0s 49us/step - loss: 0.7996 - accuracy: 0.6982 - val_loss: 1.7917 - val_accuracy: 0.4667\n",
      "Epoch 333/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.7534 - accuracy: 0.7205 - val_loss: 1.8030 - val_accuracy: 0.4889\n",
      "Epoch 334/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.8063 - accuracy: 0.6901 - val_loss: 1.8056 - val_accuracy: 0.4889\n",
      "Epoch 335/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.8245 - accuracy: 0.6830 - val_loss: 1.7918 - val_accuracy: 0.4667\n",
      "Epoch 336/1000\n",
      "855/855 [==============================] - 0s 42us/step - loss: 0.8130 - accuracy: 0.6807 - val_loss: 1.7762 - val_accuracy: 0.4667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.7791 - accuracy: 0.7053 - val_loss: 1.7532 - val_accuracy: 0.4667\n",
      "Epoch 338/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.8106 - accuracy: 0.6971 - val_loss: 1.7781 - val_accuracy: 0.5111\n",
      "Epoch 339/1000\n",
      "855/855 [==============================] - 0s 42us/step - loss: 0.8535 - accuracy: 0.6760 - val_loss: 1.7731 - val_accuracy: 0.4889\n",
      "Epoch 340/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.7859 - accuracy: 0.6947 - val_loss: 1.7361 - val_accuracy: 0.4889\n",
      "Epoch 341/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.8152 - accuracy: 0.6795 - val_loss: 1.7443 - val_accuracy: 0.4889\n",
      "Epoch 342/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.8824 - accuracy: 0.6795 - val_loss: 1.7712 - val_accuracy: 0.4667\n",
      "Epoch 343/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.8141 - accuracy: 0.7111 - val_loss: 1.8155 - val_accuracy: 0.4444\n",
      "Epoch 344/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.7878 - accuracy: 0.6947 - val_loss: 1.8825 - val_accuracy: 0.4667\n",
      "Epoch 345/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.8298 - accuracy: 0.6807 - val_loss: 1.8738 - val_accuracy: 0.4889\n",
      "Epoch 346/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.8310 - accuracy: 0.6936 - val_loss: 1.8062 - val_accuracy: 0.4889\n",
      "Epoch 347/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.8028 - accuracy: 0.6959 - val_loss: 1.8215 - val_accuracy: 0.4444\n",
      "Epoch 348/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.7934 - accuracy: 0.7298 - val_loss: 1.7924 - val_accuracy: 0.4889\n",
      "Epoch 349/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.7830 - accuracy: 0.6971 - val_loss: 1.7978 - val_accuracy: 0.4889\n",
      "Epoch 350/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.7891 - accuracy: 0.7099 - val_loss: 1.8101 - val_accuracy: 0.4667\n",
      "Epoch 351/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.8292 - accuracy: 0.6784 - val_loss: 1.7951 - val_accuracy: 0.4889\n",
      "Epoch 352/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.8408 - accuracy: 0.6702 - val_loss: 1.8053 - val_accuracy: 0.4667\n",
      "Epoch 353/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.8370 - accuracy: 0.6959 - val_loss: 1.8144 - val_accuracy: 0.4667\n",
      "Epoch 354/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.8125 - accuracy: 0.6830 - val_loss: 1.7941 - val_accuracy: 0.4667\n",
      "Epoch 355/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.8403 - accuracy: 0.6784 - val_loss: 1.7922 - val_accuracy: 0.5111\n",
      "Epoch 356/1000\n",
      "855/855 [==============================] - 0s 50us/step - loss: 0.7679 - accuracy: 0.7053 - val_loss: 1.8072 - val_accuracy: 0.4889\n",
      "Epoch 357/1000\n",
      "855/855 [==============================] - 0s 55us/step - loss: 0.8105 - accuracy: 0.6854 - val_loss: 1.7871 - val_accuracy: 0.4222\n",
      "Epoch 358/1000\n",
      "855/855 [==============================] - 0s 49us/step - loss: 0.7662 - accuracy: 0.7123 - val_loss: 1.7786 - val_accuracy: 0.4444\n",
      "Epoch 359/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.7571 - accuracy: 0.7111 - val_loss: 1.7709 - val_accuracy: 0.5111\n",
      "Epoch 360/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.8402 - accuracy: 0.6784 - val_loss: 1.7576 - val_accuracy: 0.4889\n",
      "Epoch 361/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.7916 - accuracy: 0.7064 - val_loss: 1.7175 - val_accuracy: 0.4444\n",
      "Epoch 362/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.7959 - accuracy: 0.7088 - val_loss: 1.7185 - val_accuracy: 0.4667\n",
      "Epoch 363/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 0.8198 - accuracy: 0.7064 - val_loss: 1.6886 - val_accuracy: 0.4667\n",
      "Epoch 364/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.8173 - accuracy: 0.6784 - val_loss: 1.7585 - val_accuracy: 0.4889\n",
      "Epoch 365/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.7767 - accuracy: 0.7041 - val_loss: 1.8286 - val_accuracy: 0.4889\n",
      "Epoch 366/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.7824 - accuracy: 0.7076 - val_loss: 1.8327 - val_accuracy: 0.4667\n",
      "Epoch 367/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.7910 - accuracy: 0.6912 - val_loss: 1.7955 - val_accuracy: 0.4889\n",
      "Epoch 368/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.7541 - accuracy: 0.7216 - val_loss: 1.7754 - val_accuracy: 0.4889\n",
      "Epoch 369/1000\n",
      "855/855 [==============================] - 0s 54us/step - loss: 0.7823 - accuracy: 0.7064 - val_loss: 1.7699 - val_accuracy: 0.4889\n",
      "Epoch 370/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 0.7863 - accuracy: 0.6936 - val_loss: 1.8122 - val_accuracy: 0.4667\n",
      "Epoch 371/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.7858 - accuracy: 0.7158 - val_loss: 1.8957 - val_accuracy: 0.4444\n",
      "Epoch 372/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 0.7898 - accuracy: 0.6912 - val_loss: 1.9307 - val_accuracy: 0.4667\n",
      "Epoch 373/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.8415 - accuracy: 0.6655 - val_loss: 1.8399 - val_accuracy: 0.4667\n",
      "Epoch 374/1000\n",
      "855/855 [==============================] - 0s 51us/step - loss: 0.7973 - accuracy: 0.6795 - val_loss: 1.7792 - val_accuracy: 0.4667\n",
      "Epoch 375/1000\n",
      "855/855 [==============================] - 0s 49us/step - loss: 0.7879 - accuracy: 0.7053 - val_loss: 1.7943 - val_accuracy: 0.4667\n",
      "Epoch 376/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.8645 - accuracy: 0.6819 - val_loss: 1.8217 - val_accuracy: 0.4889\n",
      "Epoch 377/1000\n",
      "855/855 [==============================] - 0s 49us/step - loss: 0.7645 - accuracy: 0.7170 - val_loss: 1.7743 - val_accuracy: 0.4889\n",
      "Epoch 378/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.7767 - accuracy: 0.7170 - val_loss: 1.7326 - val_accuracy: 0.4889\n",
      "Epoch 379/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.7940 - accuracy: 0.6924 - val_loss: 1.7885 - val_accuracy: 0.4667\n",
      "Epoch 380/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.7536 - accuracy: 0.7181 - val_loss: 1.8104 - val_accuracy: 0.4667\n",
      "Epoch 381/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 0.7361 - accuracy: 0.7181 - val_loss: 1.8121 - val_accuracy: 0.4889\n",
      "Epoch 382/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.7911 - accuracy: 0.7076 - val_loss: 1.8540 - val_accuracy: 0.4667\n",
      "Epoch 383/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.7911 - accuracy: 0.7076 - val_loss: 1.8414 - val_accuracy: 0.4667\n",
      "Epoch 384/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.7470 - accuracy: 0.7099 - val_loss: 1.8548 - val_accuracy: 0.4667\n",
      "Epoch 385/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.8096 - accuracy: 0.6994 - val_loss: 1.8533 - val_accuracy: 0.4889\n",
      "Epoch 386/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.7662 - accuracy: 0.7111 - val_loss: 1.8477 - val_accuracy: 0.4889\n",
      "Epoch 387/1000\n",
      "855/855 [==============================] - 0s 51us/step - loss: 0.7638 - accuracy: 0.7006 - val_loss: 1.8465 - val_accuracy: 0.4889\n",
      "Epoch 388/1000\n",
      "855/855 [==============================] - 0s 49us/step - loss: 0.7451 - accuracy: 0.7170 - val_loss: 1.8458 - val_accuracy: 0.4889\n",
      "Epoch 389/1000\n",
      "855/855 [==============================] - 0s 46us/step - loss: 0.7769 - accuracy: 0.6912 - val_loss: 1.8794 - val_accuracy: 0.4889\n",
      "Epoch 390/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.7591 - accuracy: 0.7076 - val_loss: 1.8824 - val_accuracy: 0.4667\n",
      "Epoch 391/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.7694 - accuracy: 0.7076 - val_loss: 1.9143 - val_accuracy: 0.4444\n",
      "Epoch 392/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.7719 - accuracy: 0.6971 - val_loss: 1.9473 - val_accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393/1000\n",
      "855/855 [==============================] - 0s 50us/step - loss: 0.7920 - accuracy: 0.7064 - val_loss: 1.8790 - val_accuracy: 0.4444\n",
      "Epoch 394/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.7831 - accuracy: 0.7018 - val_loss: 1.8270 - val_accuracy: 0.4889\n",
      "Epoch 395/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.7378 - accuracy: 0.7053 - val_loss: 1.8123 - val_accuracy: 0.4667\n",
      "Epoch 396/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.7594 - accuracy: 0.7146 - val_loss: 1.8520 - val_accuracy: 0.4667\n",
      "Epoch 397/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.7698 - accuracy: 0.7041 - val_loss: 1.8920 - val_accuracy: 0.4667\n",
      "Epoch 398/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.7568 - accuracy: 0.7193 - val_loss: 1.8832 - val_accuracy: 0.4667\n",
      "Epoch 399/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.7672 - accuracy: 0.6982 - val_loss: 1.8797 - val_accuracy: 0.4889\n",
      "Epoch 400/1000\n",
      "855/855 [==============================] - 0s 42us/step - loss: 0.7707 - accuracy: 0.7053 - val_loss: 1.8892 - val_accuracy: 0.4889\n",
      "Epoch 401/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.7835 - accuracy: 0.6725 - val_loss: 1.8900 - val_accuracy: 0.4667\n",
      "Epoch 402/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.7606 - accuracy: 0.7041 - val_loss: 1.9073 - val_accuracy: 0.4444\n",
      "Epoch 403/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 0.7796 - accuracy: 0.7099 - val_loss: 1.9434 - val_accuracy: 0.4444\n",
      "Epoch 404/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.7675 - accuracy: 0.7170 - val_loss: 1.9356 - val_accuracy: 0.4667\n",
      "Epoch 405/1000\n",
      "855/855 [==============================] - 0s 51us/step - loss: 0.7634 - accuracy: 0.7193 - val_loss: 1.9017 - val_accuracy: 0.4667\n",
      "Epoch 406/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 0.7817 - accuracy: 0.6936 - val_loss: 1.8588 - val_accuracy: 0.4667\n",
      "Epoch 407/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 0.7358 - accuracy: 0.7275 - val_loss: 1.8397 - val_accuracy: 0.4889\n",
      "Epoch 408/1000\n",
      "855/855 [==============================] - 0s 50us/step - loss: 0.7908 - accuracy: 0.7041 - val_loss: 1.8520 - val_accuracy: 0.4667\n",
      "Epoch 409/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 0.8126 - accuracy: 0.6877 - val_loss: 1.8387 - val_accuracy: 0.4889\n",
      "Epoch 410/1000\n",
      "855/855 [==============================] - 0s 49us/step - loss: 0.7161 - accuracy: 0.7322 - val_loss: 1.8772 - val_accuracy: 0.4667\n",
      "Epoch 411/1000\n",
      "855/855 [==============================] - 0s 50us/step - loss: 0.7314 - accuracy: 0.7275 - val_loss: 1.8844 - val_accuracy: 0.4667\n",
      "Epoch 412/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.7554 - accuracy: 0.6959 - val_loss: 1.8928 - val_accuracy: 0.4667\n",
      "Epoch 413/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.7611 - accuracy: 0.6936 - val_loss: 1.9227 - val_accuracy: 0.4667\n",
      "Epoch 414/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.7212 - accuracy: 0.7474 - val_loss: 1.9217 - val_accuracy: 0.4444\n",
      "Epoch 415/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.7424 - accuracy: 0.7111 - val_loss: 1.9206 - val_accuracy: 0.4667\n",
      "Epoch 416/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.7600 - accuracy: 0.7111 - val_loss: 1.9300 - val_accuracy: 0.4444\n",
      "Epoch 417/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.7658 - accuracy: 0.6982 - val_loss: 1.9756 - val_accuracy: 0.4889\n",
      "Epoch 418/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.7162 - accuracy: 0.7345 - val_loss: 1.9745 - val_accuracy: 0.4889\n",
      "Epoch 419/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.7359 - accuracy: 0.7205 - val_loss: 1.9373 - val_accuracy: 0.4889\n",
      "Epoch 420/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.7631 - accuracy: 0.7111 - val_loss: 1.8974 - val_accuracy: 0.4667\n",
      "Epoch 421/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.7369 - accuracy: 0.7193 - val_loss: 1.9125 - val_accuracy: 0.4667\n",
      "Epoch 422/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.7349 - accuracy: 0.7135 - val_loss: 1.9400 - val_accuracy: 0.4667\n",
      "Epoch 423/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.7776 - accuracy: 0.7064 - val_loss: 1.9605 - val_accuracy: 0.4889\n",
      "Epoch 424/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.7197 - accuracy: 0.7099 - val_loss: 1.9699 - val_accuracy: 0.4667\n",
      "Epoch 425/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.7641 - accuracy: 0.6994 - val_loss: 1.9474 - val_accuracy: 0.4667\n",
      "Epoch 426/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.7404 - accuracy: 0.7146 - val_loss: 1.9485 - val_accuracy: 0.4444\n",
      "Epoch 427/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.7618 - accuracy: 0.7181 - val_loss: 1.9679 - val_accuracy: 0.4667\n",
      "Epoch 428/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.7322 - accuracy: 0.7146 - val_loss: 1.9615 - val_accuracy: 0.4667\n",
      "Epoch 429/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.7651 - accuracy: 0.7135 - val_loss: 1.9753 - val_accuracy: 0.4667\n",
      "Epoch 430/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 0.7200 - accuracy: 0.7251 - val_loss: 1.9543 - val_accuracy: 0.4667\n",
      "Epoch 431/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.7090 - accuracy: 0.7368 - val_loss: 1.9301 - val_accuracy: 0.4444\n",
      "Epoch 432/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.7709 - accuracy: 0.7076 - val_loss: 1.9327 - val_accuracy: 0.4667\n",
      "Epoch 433/1000\n",
      "855/855 [==============================] - 0s 46us/step - loss: 0.7071 - accuracy: 0.7427 - val_loss: 1.9464 - val_accuracy: 0.4889\n",
      "Epoch 434/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.7155 - accuracy: 0.7310 - val_loss: 1.9870 - val_accuracy: 0.4889\n",
      "Epoch 435/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.7300 - accuracy: 0.7158 - val_loss: 2.0232 - val_accuracy: 0.4667\n",
      "Epoch 436/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.7240 - accuracy: 0.7310 - val_loss: 2.0343 - val_accuracy: 0.4667\n",
      "Epoch 437/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.7231 - accuracy: 0.7404 - val_loss: 2.0115 - val_accuracy: 0.4444\n",
      "Epoch 438/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.7382 - accuracy: 0.7041 - val_loss: 1.9551 - val_accuracy: 0.4889\n",
      "Epoch 439/1000\n",
      "855/855 [==============================] - 0s 50us/step - loss: 0.7411 - accuracy: 0.7029 - val_loss: 1.9259 - val_accuracy: 0.5111\n",
      "Epoch 440/1000\n",
      "855/855 [==============================] - 0s 51us/step - loss: 0.7007 - accuracy: 0.7287 - val_loss: 1.9600 - val_accuracy: 0.5111\n",
      "Epoch 441/1000\n",
      "855/855 [==============================] - 0s 49us/step - loss: 0.7143 - accuracy: 0.7251 - val_loss: 2.0317 - val_accuracy: 0.4667\n",
      "Epoch 442/1000\n",
      "855/855 [==============================] - 0s 51us/step - loss: 0.7325 - accuracy: 0.7322 - val_loss: 2.0332 - val_accuracy: 0.4444\n",
      "Epoch 443/1000\n",
      "855/855 [==============================] - 0s 49us/step - loss: 0.7612 - accuracy: 0.7076 - val_loss: 1.9950 - val_accuracy: 0.4444\n",
      "Epoch 444/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 0.7221 - accuracy: 0.6971 - val_loss: 1.9463 - val_accuracy: 0.4889\n",
      "Epoch 445/1000\n",
      "855/855 [==============================] - 0s 52us/step - loss: 0.7483 - accuracy: 0.7146 - val_loss: 1.9193 - val_accuracy: 0.4889\n",
      "Epoch 446/1000\n",
      "855/855 [==============================] - 0s 51us/step - loss: 0.7377 - accuracy: 0.7158 - val_loss: 1.8785 - val_accuracy: 0.4889\n",
      "Epoch 447/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 0.7149 - accuracy: 0.7205 - val_loss: 1.8784 - val_accuracy: 0.4667\n",
      "Epoch 448/1000\n",
      "855/855 [==============================] - 0s 55us/step - loss: 0.7255 - accuracy: 0.7135 - val_loss: 1.8914 - val_accuracy: 0.4667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449/1000\n",
      "855/855 [==============================] - 0s 51us/step - loss: 0.7242 - accuracy: 0.7240 - val_loss: 1.9318 - val_accuracy: 0.5111\n",
      "Epoch 450/1000\n",
      "855/855 [==============================] - 0s 56us/step - loss: 0.7366 - accuracy: 0.6947 - val_loss: 1.9207 - val_accuracy: 0.5111\n",
      "Epoch 451/1000\n",
      "855/855 [==============================] - 0s 52us/step - loss: 0.7242 - accuracy: 0.7263 - val_loss: 1.9385 - val_accuracy: 0.5111\n",
      "Epoch 452/1000\n",
      "855/855 [==============================] - 0s 51us/step - loss: 0.7249 - accuracy: 0.7205 - val_loss: 1.9354 - val_accuracy: 0.5111\n",
      "Epoch 453/1000\n",
      "855/855 [==============================] - 0s 56us/step - loss: 0.7183 - accuracy: 0.7041 - val_loss: 1.9585 - val_accuracy: 0.4667\n",
      "Epoch 454/1000\n",
      "855/855 [==============================] - 0s 59us/step - loss: 0.7261 - accuracy: 0.7146 - val_loss: 1.9531 - val_accuracy: 0.4667\n",
      "Epoch 455/1000\n",
      "855/855 [==============================] - 0s 51us/step - loss: 0.7234 - accuracy: 0.7158 - val_loss: 1.9449 - val_accuracy: 0.4889\n",
      "Epoch 456/1000\n",
      "855/855 [==============================] - 0s 49us/step - loss: 0.7012 - accuracy: 0.7322 - val_loss: 1.9210 - val_accuracy: 0.5111\n",
      "Epoch 457/1000\n",
      "855/855 [==============================] - 0s 49us/step - loss: 0.7202 - accuracy: 0.7263 - val_loss: 1.9417 - val_accuracy: 0.4889\n",
      "Epoch 458/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 0.7137 - accuracy: 0.7240 - val_loss: 2.0033 - val_accuracy: 0.4889\n",
      "Epoch 459/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.7384 - accuracy: 0.6994 - val_loss: 2.0141 - val_accuracy: 0.4889\n",
      "Epoch 460/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.7399 - accuracy: 0.7380 - val_loss: 1.9995 - val_accuracy: 0.4667\n",
      "Epoch 461/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 0.7326 - accuracy: 0.7111 - val_loss: 2.0056 - val_accuracy: 0.4889\n",
      "Epoch 462/1000\n",
      "855/855 [==============================] - 0s 49us/step - loss: 0.7340 - accuracy: 0.7099 - val_loss: 2.0171 - val_accuracy: 0.4889\n",
      "Epoch 463/1000\n",
      "855/855 [==============================] - 0s 49us/step - loss: 0.7309 - accuracy: 0.7146 - val_loss: 1.9899 - val_accuracy: 0.4889\n",
      "Epoch 464/1000\n",
      "855/855 [==============================] - 0s 52us/step - loss: 0.6750 - accuracy: 0.7602 - val_loss: 2.0172 - val_accuracy: 0.5111\n",
      "Epoch 465/1000\n",
      "855/855 [==============================] - 0s 50us/step - loss: 0.7253 - accuracy: 0.7099 - val_loss: 2.0076 - val_accuracy: 0.5111\n",
      "Epoch 466/1000\n",
      "855/855 [==============================] - 0s 49us/step - loss: 0.7220 - accuracy: 0.7345 - val_loss: 1.9685 - val_accuracy: 0.4667\n",
      "Epoch 467/1000\n",
      "855/855 [==============================] - ETA: 0s - loss: 0.6336 - accuracy: 0.73 - 0s 51us/step - loss: 0.7224 - accuracy: 0.7404 - val_loss: 1.9634 - val_accuracy: 0.4222\n",
      "Epoch 468/1000\n",
      "855/855 [==============================] - 0s 54us/step - loss: 0.7146 - accuracy: 0.7345 - val_loss: 1.9693 - val_accuracy: 0.4444\n",
      "Epoch 469/1000\n",
      "855/855 [==============================] - 0s 52us/step - loss: 0.6932 - accuracy: 0.7345 - val_loss: 1.9939 - val_accuracy: 0.4667\n",
      "Epoch 470/1000\n",
      "855/855 [==============================] - 0s 49us/step - loss: 0.6856 - accuracy: 0.7322 - val_loss: 2.0246 - val_accuracy: 0.4667\n",
      "Epoch 471/1000\n",
      "855/855 [==============================] - 0s 42us/step - loss: 0.7224 - accuracy: 0.7181 - val_loss: 2.0506 - val_accuracy: 0.4889\n",
      "Epoch 472/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6997 - accuracy: 0.7216 - val_loss: 2.0882 - val_accuracy: 0.4667\n",
      "Epoch 473/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6982 - accuracy: 0.7450 - val_loss: 2.0940 - val_accuracy: 0.4667\n",
      "Epoch 474/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.7094 - accuracy: 0.7287 - val_loss: 2.0822 - val_accuracy: 0.4667\n",
      "Epoch 475/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.7755 - accuracy: 0.7158 - val_loss: 2.0489 - val_accuracy: 0.4667\n",
      "Epoch 476/1000\n",
      "855/855 [==============================] - 0s 49us/step - loss: 0.7447 - accuracy: 0.7064 - val_loss: 2.0756 - val_accuracy: 0.4667\n",
      "Epoch 477/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 0.7402 - accuracy: 0.7170 - val_loss: 2.0570 - val_accuracy: 0.4667\n",
      "Epoch 478/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6989 - accuracy: 0.7263 - val_loss: 2.0565 - val_accuracy: 0.4444\n",
      "Epoch 479/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.7037 - accuracy: 0.7263 - val_loss: 2.0504 - val_accuracy: 0.4667\n",
      "Epoch 480/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.7240 - accuracy: 0.7216 - val_loss: 2.0349 - val_accuracy: 0.4444\n",
      "Epoch 481/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6942 - accuracy: 0.7251 - val_loss: 2.0195 - val_accuracy: 0.4444\n",
      "Epoch 482/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6923 - accuracy: 0.7368 - val_loss: 1.9512 - val_accuracy: 0.4667\n",
      "Epoch 483/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 0.7568 - accuracy: 0.7298 - val_loss: 1.9230 - val_accuracy: 0.4889\n",
      "Epoch 484/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6973 - accuracy: 0.7345 - val_loss: 1.9161 - val_accuracy: 0.4889\n",
      "Epoch 485/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6910 - accuracy: 0.7333 - val_loss: 1.9329 - val_accuracy: 0.5111\n",
      "Epoch 486/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.7008 - accuracy: 0.7427 - val_loss: 1.9847 - val_accuracy: 0.5111\n",
      "Epoch 487/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 0.6814 - accuracy: 0.7228 - val_loss: 2.0128 - val_accuracy: 0.5111\n",
      "Epoch 488/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6919 - accuracy: 0.7310 - val_loss: 2.0161 - val_accuracy: 0.5111\n",
      "Epoch 489/1000\n",
      "855/855 [==============================] - 0s 50us/step - loss: 0.7140 - accuracy: 0.7298 - val_loss: 1.9804 - val_accuracy: 0.4889\n",
      "Epoch 490/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.7605 - accuracy: 0.7123 - val_loss: 1.9891 - val_accuracy: 0.4444\n",
      "Epoch 491/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.6734 - accuracy: 0.7275 - val_loss: 2.0169 - val_accuracy: 0.4889\n",
      "Epoch 492/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.7187 - accuracy: 0.7380 - val_loss: 2.0206 - val_accuracy: 0.4889\n",
      "Epoch 493/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6956 - accuracy: 0.7368 - val_loss: 2.0398 - val_accuracy: 0.4889\n",
      "Epoch 494/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6715 - accuracy: 0.7228 - val_loss: 2.1074 - val_accuracy: 0.4667\n",
      "Epoch 495/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.7225 - accuracy: 0.7135 - val_loss: 2.1098 - val_accuracy: 0.4667\n",
      "Epoch 496/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.7051 - accuracy: 0.7322 - val_loss: 2.1213 - val_accuracy: 0.4667\n",
      "Epoch 497/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.6849 - accuracy: 0.7427 - val_loss: 2.0524 - val_accuracy: 0.4889\n",
      "Epoch 498/1000\n",
      "855/855 [==============================] - 0s 52us/step - loss: 0.7120 - accuracy: 0.7275 - val_loss: 2.0247 - val_accuracy: 0.4889\n",
      "Epoch 499/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 0.6827 - accuracy: 0.7462 - val_loss: 2.0013 - val_accuracy: 0.4667\n",
      "Epoch 500/1000\n",
      "855/855 [==============================] - 0s 46us/step - loss: 0.7392 - accuracy: 0.7099 - val_loss: 2.0877 - val_accuracy: 0.4667\n",
      "Epoch 501/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.6750 - accuracy: 0.7474 - val_loss: 2.1384 - val_accuracy: 0.4667\n",
      "Epoch 502/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.7209 - accuracy: 0.7170 - val_loss: 2.1524 - val_accuracy: 0.4667\n",
      "Epoch 503/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.7075 - accuracy: 0.7240 - val_loss: 2.1023 - val_accuracy: 0.4667\n",
      "Epoch 504/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.7128 - accuracy: 0.7240 - val_loss: 2.0829 - val_accuracy: 0.4667\n",
      "Epoch 505/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6760 - accuracy: 0.7368 - val_loss: 2.1083 - val_accuracy: 0.4667\n",
      "Epoch 506/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6706 - accuracy: 0.7392 - val_loss: 2.0972 - val_accuracy: 0.4667\n",
      "Epoch 507/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.7064 - accuracy: 0.7263 - val_loss: 2.0811 - val_accuracy: 0.4667\n",
      "Epoch 508/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6850 - accuracy: 0.7357 - val_loss: 2.1009 - val_accuracy: 0.4667\n",
      "Epoch 509/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.7023 - accuracy: 0.7392 - val_loss: 2.1018 - val_accuracy: 0.4444\n",
      "Epoch 510/1000\n",
      "855/855 [==============================] - 0s 49us/step - loss: 0.7104 - accuracy: 0.7205 - val_loss: 2.0832 - val_accuracy: 0.4667\n",
      "Epoch 511/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.7153 - accuracy: 0.7357 - val_loss: 2.0856 - val_accuracy: 0.4667\n",
      "Epoch 512/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6800 - accuracy: 0.7462 - val_loss: 2.0669 - val_accuracy: 0.4667\n",
      "Epoch 513/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6884 - accuracy: 0.7205 - val_loss: 2.0730 - val_accuracy: 0.4889\n",
      "Epoch 514/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6916 - accuracy: 0.7427 - val_loss: 2.0736 - val_accuracy: 0.4889\n",
      "Epoch 515/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6703 - accuracy: 0.7474 - val_loss: 2.0738 - val_accuracy: 0.4667\n",
      "Epoch 516/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.7029 - accuracy: 0.7357 - val_loss: 2.0890 - val_accuracy: 0.4667\n",
      "Epoch 517/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6800 - accuracy: 0.7392 - val_loss: 2.0806 - val_accuracy: 0.4667\n",
      "Epoch 518/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.7280 - accuracy: 0.7111 - val_loss: 2.0774 - val_accuracy: 0.4667\n",
      "Epoch 519/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.7158 - accuracy: 0.7287 - val_loss: 2.0896 - val_accuracy: 0.4667\n",
      "Epoch 520/1000\n",
      "855/855 [==============================] - 0s 49us/step - loss: 0.6591 - accuracy: 0.7462 - val_loss: 2.0948 - val_accuracy: 0.4667\n",
      "Epoch 521/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6723 - accuracy: 0.7450 - val_loss: 2.1482 - val_accuracy: 0.4444\n",
      "Epoch 522/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6893 - accuracy: 0.7404 - val_loss: 2.1864 - val_accuracy: 0.4667\n",
      "Epoch 523/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6597 - accuracy: 0.7404 - val_loss: 2.1698 - val_accuracy: 0.4667\n",
      "Epoch 524/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6948 - accuracy: 0.7251 - val_loss: 2.1579 - val_accuracy: 0.4667\n",
      "Epoch 525/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.7056 - accuracy: 0.7450 - val_loss: 2.1381 - val_accuracy: 0.4444\n",
      "Epoch 526/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.7011 - accuracy: 0.7485 - val_loss: 2.0949 - val_accuracy: 0.4444\n",
      "Epoch 527/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.7159 - accuracy: 0.7310 - val_loss: 2.1017 - val_accuracy: 0.4667\n",
      "Epoch 528/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.6745 - accuracy: 0.7368 - val_loss: 2.1548 - val_accuracy: 0.4667\n",
      "Epoch 529/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.7243 - accuracy: 0.7392 - val_loss: 2.2030 - val_accuracy: 0.4444\n",
      "Epoch 530/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.7351 - accuracy: 0.7310 - val_loss: 2.1581 - val_accuracy: 0.4444\n",
      "Epoch 531/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6895 - accuracy: 0.7404 - val_loss: 2.1195 - val_accuracy: 0.4444\n",
      "Epoch 532/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6637 - accuracy: 0.7579 - val_loss: 2.1219 - val_accuracy: 0.4667\n",
      "Epoch 533/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.7166 - accuracy: 0.7263 - val_loss: 2.1390 - val_accuracy: 0.4889\n",
      "Epoch 534/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6681 - accuracy: 0.7649 - val_loss: 2.1326 - val_accuracy: 0.4667\n",
      "Epoch 535/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6807 - accuracy: 0.7532 - val_loss: 2.0684 - val_accuracy: 0.4444\n",
      "Epoch 536/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.7629 - accuracy: 0.7146 - val_loss: 2.0279 - val_accuracy: 0.4444\n",
      "Epoch 537/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6772 - accuracy: 0.7333 - val_loss: 2.0114 - val_accuracy: 0.4667\n",
      "Epoch 538/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6374 - accuracy: 0.7602 - val_loss: 2.0436 - val_accuracy: 0.4667\n",
      "Epoch 539/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6715 - accuracy: 0.7485 - val_loss: 2.0458 - val_accuracy: 0.4444\n",
      "Epoch 540/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.7017 - accuracy: 0.7251 - val_loss: 2.0776 - val_accuracy: 0.4889\n",
      "Epoch 541/1000\n",
      "855/855 [==============================] - 0s 46us/step - loss: 0.6870 - accuracy: 0.7146 - val_loss: 2.1049 - val_accuracy: 0.4444\n",
      "Epoch 542/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6599 - accuracy: 0.7520 - val_loss: 2.1277 - val_accuracy: 0.4444\n",
      "Epoch 543/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6687 - accuracy: 0.7427 - val_loss: 2.1204 - val_accuracy: 0.4667\n",
      "Epoch 544/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6778 - accuracy: 0.7357 - val_loss: 2.1203 - val_accuracy: 0.4667\n",
      "Epoch 545/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6686 - accuracy: 0.7404 - val_loss: 2.1155 - val_accuracy: 0.4667\n",
      "Epoch 546/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.6412 - accuracy: 0.7485 - val_loss: 2.1488 - val_accuracy: 0.4667\n",
      "Epoch 547/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6651 - accuracy: 0.7532 - val_loss: 2.1517 - val_accuracy: 0.4444\n",
      "Epoch 548/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6764 - accuracy: 0.7462 - val_loss: 2.1532 - val_accuracy: 0.4667\n",
      "Epoch 549/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6545 - accuracy: 0.7427 - val_loss: 2.1388 - val_accuracy: 0.4889\n",
      "Epoch 550/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6808 - accuracy: 0.7497 - val_loss: 2.1261 - val_accuracy: 0.4889\n",
      "Epoch 551/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.7100 - accuracy: 0.7275 - val_loss: 2.1299 - val_accuracy: 0.4444\n",
      "Epoch 552/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6762 - accuracy: 0.7357 - val_loss: 2.1526 - val_accuracy: 0.4222\n",
      "Epoch 553/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6362 - accuracy: 0.7544 - val_loss: 2.1398 - val_accuracy: 0.4222\n",
      "Epoch 554/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6926 - accuracy: 0.7193 - val_loss: 2.1595 - val_accuracy: 0.4444\n",
      "Epoch 555/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6988 - accuracy: 0.7333 - val_loss: 2.1652 - val_accuracy: 0.4444\n",
      "Epoch 556/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.6622 - accuracy: 0.7474 - val_loss: 2.1629 - val_accuracy: 0.4444\n",
      "Epoch 557/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6658 - accuracy: 0.7462 - val_loss: 2.1677 - val_accuracy: 0.4444\n",
      "Epoch 558/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6633 - accuracy: 0.7602 - val_loss: 2.1790 - val_accuracy: 0.4222\n",
      "Epoch 559/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.6656 - accuracy: 0.7333 - val_loss: 2.1701 - val_accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 560/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6276 - accuracy: 0.7520 - val_loss: 2.1768 - val_accuracy: 0.4222\n",
      "Epoch 561/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6649 - accuracy: 0.7509 - val_loss: 2.1566 - val_accuracy: 0.4444\n",
      "Epoch 562/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6628 - accuracy: 0.7439 - val_loss: 2.1637 - val_accuracy: 0.4222\n",
      "Epoch 563/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6773 - accuracy: 0.7322 - val_loss: 2.2054 - val_accuracy: 0.4222\n",
      "Epoch 564/1000\n",
      "855/855 [==============================] - 0s 42us/step - loss: 0.6586 - accuracy: 0.7509 - val_loss: 2.1903 - val_accuracy: 0.4222\n",
      "Epoch 565/1000\n",
      "855/855 [==============================] - 0s 42us/step - loss: 0.6336 - accuracy: 0.7696 - val_loss: 2.1917 - val_accuracy: 0.4222\n",
      "Epoch 566/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6723 - accuracy: 0.7427 - val_loss: 2.1702 - val_accuracy: 0.4444\n",
      "Epoch 567/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6705 - accuracy: 0.7368 - val_loss: 2.1712 - val_accuracy: 0.4222\n",
      "Epoch 568/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6750 - accuracy: 0.7404 - val_loss: 2.1736 - val_accuracy: 0.4222\n",
      "Epoch 569/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6764 - accuracy: 0.7450 - val_loss: 2.1935 - val_accuracy: 0.4222\n",
      "Epoch 570/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6732 - accuracy: 0.7509 - val_loss: 2.2095 - val_accuracy: 0.4222\n",
      "Epoch 571/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6612 - accuracy: 0.7485 - val_loss: 2.2633 - val_accuracy: 0.4222\n",
      "Epoch 572/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.6672 - accuracy: 0.7450 - val_loss: 2.2420 - val_accuracy: 0.4444\n",
      "Epoch 573/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6448 - accuracy: 0.7427 - val_loss: 2.1700 - val_accuracy: 0.4444\n",
      "Epoch 574/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.7013 - accuracy: 0.7474 - val_loss: 2.1715 - val_accuracy: 0.4222\n",
      "Epoch 575/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.7046 - accuracy: 0.7368 - val_loss: 2.1803 - val_accuracy: 0.4222\n",
      "Epoch 576/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6617 - accuracy: 0.7392 - val_loss: 2.1445 - val_accuracy: 0.4444\n",
      "Epoch 577/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6564 - accuracy: 0.7439 - val_loss: 2.1323 - val_accuracy: 0.4444\n",
      "Epoch 578/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.6487 - accuracy: 0.7450 - val_loss: 2.1496 - val_accuracy: 0.4444\n",
      "Epoch 579/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6856 - accuracy: 0.7368 - val_loss: 2.1268 - val_accuracy: 0.4667\n",
      "Epoch 580/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6658 - accuracy: 0.7345 - val_loss: 2.1356 - val_accuracy: 0.4667\n",
      "Epoch 581/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6240 - accuracy: 0.7696 - val_loss: 2.1879 - val_accuracy: 0.4667\n",
      "Epoch 582/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6188 - accuracy: 0.7661 - val_loss: 2.1753 - val_accuracy: 0.4889\n",
      "Epoch 583/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6437 - accuracy: 0.7614 - val_loss: 2.1507 - val_accuracy: 0.4667\n",
      "Epoch 584/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6723 - accuracy: 0.7532 - val_loss: 2.1394 - val_accuracy: 0.4667\n",
      "Epoch 585/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6383 - accuracy: 0.7439 - val_loss: 2.1602 - val_accuracy: 0.4889\n",
      "Epoch 586/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6512 - accuracy: 0.7520 - val_loss: 2.2190 - val_accuracy: 0.4667\n",
      "Epoch 587/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6441 - accuracy: 0.7684 - val_loss: 2.2220 - val_accuracy: 0.4889\n",
      "Epoch 588/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6391 - accuracy: 0.7579 - val_loss: 2.2108 - val_accuracy: 0.4889\n",
      "Epoch 589/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6814 - accuracy: 0.7415 - val_loss: 2.2171 - val_accuracy: 0.4889\n",
      "Epoch 590/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6566 - accuracy: 0.7520 - val_loss: 2.2080 - val_accuracy: 0.4889\n",
      "Epoch 591/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.6770 - accuracy: 0.7415 - val_loss: 2.1424 - val_accuracy: 0.4889\n",
      "Epoch 592/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.6520 - accuracy: 0.7602 - val_loss: 2.1268 - val_accuracy: 0.4889\n",
      "Epoch 593/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.6591 - accuracy: 0.7462 - val_loss: 2.1969 - val_accuracy: 0.4889\n",
      "Epoch 594/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6617 - accuracy: 0.7310 - val_loss: 2.2483 - val_accuracy: 0.4889\n",
      "Epoch 595/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6329 - accuracy: 0.7602 - val_loss: 2.2409 - val_accuracy: 0.4667\n",
      "Epoch 596/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6356 - accuracy: 0.7556 - val_loss: 2.1999 - val_accuracy: 0.4667\n",
      "Epoch 597/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6464 - accuracy: 0.7520 - val_loss: 2.2176 - val_accuracy: 0.4444\n",
      "Epoch 598/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6573 - accuracy: 0.7637 - val_loss: 2.2636 - val_accuracy: 0.4667\n",
      "Epoch 599/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6950 - accuracy: 0.7450 - val_loss: 2.2854 - val_accuracy: 0.4444\n",
      "Epoch 600/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6756 - accuracy: 0.7380 - val_loss: 2.2406 - val_accuracy: 0.4444\n",
      "Epoch 601/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.7122 - accuracy: 0.7158 - val_loss: 2.1954 - val_accuracy: 0.4444\n",
      "Epoch 602/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.7058 - accuracy: 0.7298 - val_loss: 2.1704 - val_accuracy: 0.4444\n",
      "Epoch 603/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6493 - accuracy: 0.7474 - val_loss: 2.1666 - val_accuracy: 0.4667\n",
      "Epoch 604/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6320 - accuracy: 0.7427 - val_loss: 2.1844 - val_accuracy: 0.4667\n",
      "Epoch 605/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 0.6857 - accuracy: 0.7462 - val_loss: 2.1833 - val_accuracy: 0.4667\n",
      "Epoch 606/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.6521 - accuracy: 0.7415 - val_loss: 2.2088 - val_accuracy: 0.4667\n",
      "Epoch 607/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.6616 - accuracy: 0.7497 - val_loss: 2.2348 - val_accuracy: 0.4667\n",
      "Epoch 608/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6747 - accuracy: 0.7380 - val_loss: 2.2231 - val_accuracy: 0.4667\n",
      "Epoch 609/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.7048 - accuracy: 0.7450 - val_loss: 2.2320 - val_accuracy: 0.4667\n",
      "Epoch 610/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6776 - accuracy: 0.7275 - val_loss: 2.2354 - val_accuracy: 0.4667\n",
      "Epoch 611/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.6419 - accuracy: 0.7474 - val_loss: 2.2550 - val_accuracy: 0.4667\n",
      "Epoch 612/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6648 - accuracy: 0.7474 - val_loss: 2.2615 - val_accuracy: 0.4667\n",
      "Epoch 613/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.6198 - accuracy: 0.7626 - val_loss: 2.2386 - val_accuracy: 0.4889\n",
      "Epoch 614/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6577 - accuracy: 0.7614 - val_loss: 2.2801 - val_accuracy: 0.4889\n",
      "Epoch 615/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.6526 - accuracy: 0.7556 - val_loss: 2.2768 - val_accuracy: 0.4667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 616/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6540 - accuracy: 0.7614 - val_loss: 2.2438 - val_accuracy: 0.4889\n",
      "Epoch 617/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.6584 - accuracy: 0.7520 - val_loss: 2.1363 - val_accuracy: 0.4889\n",
      "Epoch 618/1000\n",
      "855/855 [==============================] - 0s 50us/step - loss: 0.6837 - accuracy: 0.7251 - val_loss: 2.0852 - val_accuracy: 0.4667\n",
      "Epoch 619/1000\n",
      "855/855 [==============================] - 0s 42us/step - loss: 0.6507 - accuracy: 0.7567 - val_loss: 2.0929 - val_accuracy: 0.4667\n",
      "Epoch 620/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6640 - accuracy: 0.7567 - val_loss: 2.1122 - val_accuracy: 0.4889\n",
      "Epoch 621/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6544 - accuracy: 0.7520 - val_loss: 2.1007 - val_accuracy: 0.4667\n",
      "Epoch 622/1000\n",
      "855/855 [==============================] - 0s 42us/step - loss: 0.6822 - accuracy: 0.7427 - val_loss: 2.1421 - val_accuracy: 0.4667\n",
      "Epoch 623/1000\n",
      "855/855 [==============================] - 0s 42us/step - loss: 0.6594 - accuracy: 0.7556 - val_loss: 2.1867 - val_accuracy: 0.4222\n",
      "Epoch 624/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6569 - accuracy: 0.7532 - val_loss: 2.1577 - val_accuracy: 0.4222\n",
      "Epoch 625/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6282 - accuracy: 0.7731 - val_loss: 2.1723 - val_accuracy: 0.4222\n",
      "Epoch 626/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6331 - accuracy: 0.7485 - val_loss: 2.1714 - val_accuracy: 0.4667\n",
      "Epoch 627/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6185 - accuracy: 0.7556 - val_loss: 2.1537 - val_accuracy: 0.4667\n",
      "Epoch 628/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6496 - accuracy: 0.7450 - val_loss: 2.1693 - val_accuracy: 0.4889\n",
      "Epoch 629/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6296 - accuracy: 0.7556 - val_loss: 2.1163 - val_accuracy: 0.4889\n",
      "Epoch 630/1000\n",
      "855/855 [==============================] - 0s 42us/step - loss: 0.6502 - accuracy: 0.7661 - val_loss: 2.1408 - val_accuracy: 0.4667\n",
      "Epoch 631/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.6026 - accuracy: 0.7602 - val_loss: 2.2106 - val_accuracy: 0.4667\n",
      "Epoch 632/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.6121 - accuracy: 0.7556 - val_loss: 2.2456 - val_accuracy: 0.4667\n",
      "Epoch 633/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6844 - accuracy: 0.7591 - val_loss: 2.2551 - val_accuracy: 0.4667\n",
      "Epoch 634/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6145 - accuracy: 0.7661 - val_loss: 2.1922 - val_accuracy: 0.4889\n",
      "Epoch 635/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6810 - accuracy: 0.7345 - val_loss: 2.1670 - val_accuracy: 0.5111\n",
      "Epoch 636/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6175 - accuracy: 0.7754 - val_loss: 2.1351 - val_accuracy: 0.5111\n",
      "Epoch 637/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6938 - accuracy: 0.7310 - val_loss: 2.1105 - val_accuracy: 0.5111\n",
      "Epoch 638/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6444 - accuracy: 0.7673 - val_loss: 2.0832 - val_accuracy: 0.4889\n",
      "Epoch 639/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6358 - accuracy: 0.7661 - val_loss: 2.0938 - val_accuracy: 0.4889\n",
      "Epoch 640/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6779 - accuracy: 0.7556 - val_loss: 2.1194 - val_accuracy: 0.4889\n",
      "Epoch 641/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6383 - accuracy: 0.7602 - val_loss: 2.0786 - val_accuracy: 0.4889\n",
      "Epoch 642/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.6622 - accuracy: 0.7591 - val_loss: 2.0485 - val_accuracy: 0.4667\n",
      "Epoch 643/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6796 - accuracy: 0.7567 - val_loss: 2.0090 - val_accuracy: 0.4444\n",
      "Epoch 644/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.6566 - accuracy: 0.7544 - val_loss: 2.0190 - val_accuracy: 0.4444\n",
      "Epoch 645/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6500 - accuracy: 0.7509 - val_loss: 2.0608 - val_accuracy: 0.4444\n",
      "Epoch 646/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6726 - accuracy: 0.7415 - val_loss: 2.0912 - val_accuracy: 0.4444\n",
      "Epoch 647/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6495 - accuracy: 0.7474 - val_loss: 2.1378 - val_accuracy: 0.4444\n",
      "Epoch 648/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6314 - accuracy: 0.7743 - val_loss: 2.1608 - val_accuracy: 0.4667\n",
      "Epoch 649/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6115 - accuracy: 0.7427 - val_loss: 2.1959 - val_accuracy: 0.4667\n",
      "Epoch 650/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6558 - accuracy: 0.7626 - val_loss: 2.1882 - val_accuracy: 0.4667\n",
      "Epoch 651/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6627 - accuracy: 0.7614 - val_loss: 2.1581 - val_accuracy: 0.5111\n",
      "Epoch 652/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.6469 - accuracy: 0.7544 - val_loss: 2.1543 - val_accuracy: 0.5111\n",
      "Epoch 653/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6649 - accuracy: 0.7357 - val_loss: 2.1156 - val_accuracy: 0.4667\n",
      "Epoch 654/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6531 - accuracy: 0.7439 - val_loss: 2.0741 - val_accuracy: 0.4889\n",
      "Epoch 655/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6184 - accuracy: 0.7696 - val_loss: 2.0566 - val_accuracy: 0.4889\n",
      "Epoch 656/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6502 - accuracy: 0.7497 - val_loss: 2.0769 - val_accuracy: 0.4889\n",
      "Epoch 657/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6047 - accuracy: 0.7602 - val_loss: 2.0787 - val_accuracy: 0.4889\n",
      "Epoch 658/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6841 - accuracy: 0.7404 - val_loss: 2.0851 - val_accuracy: 0.4889\n",
      "Epoch 659/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6005 - accuracy: 0.7649 - val_loss: 2.1110 - val_accuracy: 0.4667\n",
      "Epoch 660/1000\n",
      "855/855 [==============================] - 0s 42us/step - loss: 0.6536 - accuracy: 0.7637 - val_loss: 2.1478 - val_accuracy: 0.4667\n",
      "Epoch 661/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6404 - accuracy: 0.7591 - val_loss: 2.1740 - val_accuracy: 0.4667\n",
      "Epoch 662/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6829 - accuracy: 0.7509 - val_loss: 2.1663 - val_accuracy: 0.4889\n",
      "Epoch 663/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6862 - accuracy: 0.7404 - val_loss: 2.1419 - val_accuracy: 0.4889\n",
      "Epoch 664/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6036 - accuracy: 0.7696 - val_loss: 2.1461 - val_accuracy: 0.4667\n",
      "Epoch 665/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6449 - accuracy: 0.7520 - val_loss: 2.1925 - val_accuracy: 0.4667\n",
      "Epoch 666/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.6143 - accuracy: 0.7626 - val_loss: 2.2220 - val_accuracy: 0.4667\n",
      "Epoch 667/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6126 - accuracy: 0.7731 - val_loss: 2.1905 - val_accuracy: 0.4444\n",
      "Epoch 668/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.6856 - accuracy: 0.7368 - val_loss: 2.1944 - val_accuracy: 0.4889\n",
      "Epoch 669/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6170 - accuracy: 0.7708 - val_loss: 2.2060 - val_accuracy: 0.5111\n",
      "Epoch 670/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6153 - accuracy: 0.7462 - val_loss: 2.2000 - val_accuracy: 0.4889\n",
      "Epoch 671/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6107 - accuracy: 0.7661 - val_loss: 2.1798 - val_accuracy: 0.4889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 672/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.6217 - accuracy: 0.7520 - val_loss: 2.1884 - val_accuracy: 0.5111\n",
      "Epoch 673/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6499 - accuracy: 0.7579 - val_loss: 2.1850 - val_accuracy: 0.5111\n",
      "Epoch 674/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6330 - accuracy: 0.7532 - val_loss: 2.1844 - val_accuracy: 0.5333\n",
      "Epoch 675/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.6195 - accuracy: 0.7579 - val_loss: 2.1780 - val_accuracy: 0.4889\n",
      "Epoch 676/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6297 - accuracy: 0.7427 - val_loss: 2.1428 - val_accuracy: 0.4667\n",
      "Epoch 677/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6311 - accuracy: 0.7661 - val_loss: 2.1633 - val_accuracy: 0.4444\n",
      "Epoch 678/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6144 - accuracy: 0.7719 - val_loss: 2.2345 - val_accuracy: 0.4667\n",
      "Epoch 679/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6573 - accuracy: 0.7567 - val_loss: 2.2504 - val_accuracy: 0.4667\n",
      "Epoch 680/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6181 - accuracy: 0.7602 - val_loss: 2.2596 - val_accuracy: 0.4444\n",
      "Epoch 681/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6204 - accuracy: 0.7673 - val_loss: 2.2182 - val_accuracy: 0.4444\n",
      "Epoch 682/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6289 - accuracy: 0.7637 - val_loss: 2.1790 - val_accuracy: 0.4444\n",
      "Epoch 683/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6145 - accuracy: 0.7485 - val_loss: 2.1638 - val_accuracy: 0.4667\n",
      "Epoch 684/1000\n",
      "855/855 [==============================] - 0s 42us/step - loss: 0.5928 - accuracy: 0.7719 - val_loss: 2.2027 - val_accuracy: 0.5111\n",
      "Epoch 685/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6168 - accuracy: 0.7673 - val_loss: 2.1597 - val_accuracy: 0.5111\n",
      "Epoch 686/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6146 - accuracy: 0.7708 - val_loss: 2.1552 - val_accuracy: 0.4889\n",
      "Epoch 687/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.6580 - accuracy: 0.7415 - val_loss: 2.1650 - val_accuracy: 0.4889\n",
      "Epoch 688/1000\n",
      "855/855 [==============================] - 0s 49us/step - loss: 0.6079 - accuracy: 0.7626 - val_loss: 2.1732 - val_accuracy: 0.4667\n",
      "Epoch 689/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 0.6421 - accuracy: 0.7637 - val_loss: 2.2176 - val_accuracy: 0.4444\n",
      "Epoch 690/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.6357 - accuracy: 0.7673 - val_loss: 2.2598 - val_accuracy: 0.4444\n",
      "Epoch 691/1000\n",
      "855/855 [==============================] - 0s 42us/step - loss: 0.6361 - accuracy: 0.7497 - val_loss: 2.2533 - val_accuracy: 0.4667\n",
      "Epoch 692/1000\n",
      "855/855 [==============================] - 0s 42us/step - loss: 0.6823 - accuracy: 0.7380 - val_loss: 2.2333 - val_accuracy: 0.4444\n",
      "Epoch 693/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6061 - accuracy: 0.7684 - val_loss: 2.2783 - val_accuracy: 0.4667\n",
      "Epoch 694/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6156 - accuracy: 0.7591 - val_loss: 2.3436 - val_accuracy: 0.4667\n",
      "Epoch 695/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.6480 - accuracy: 0.7719 - val_loss: 2.3745 - val_accuracy: 0.4667\n",
      "Epoch 696/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6002 - accuracy: 0.7766 - val_loss: 2.3657 - val_accuracy: 0.4889\n",
      "Epoch 697/1000\n",
      "855/855 [==============================] - 0s 42us/step - loss: 0.6039 - accuracy: 0.7673 - val_loss: 2.3626 - val_accuracy: 0.4444\n",
      "Epoch 698/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6947 - accuracy: 0.7322 - val_loss: 2.3602 - val_accuracy: 0.4222\n",
      "Epoch 699/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6378 - accuracy: 0.7579 - val_loss: 2.3380 - val_accuracy: 0.4444\n",
      "Epoch 700/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6372 - accuracy: 0.7579 - val_loss: 2.3292 - val_accuracy: 0.4667\n",
      "Epoch 701/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6240 - accuracy: 0.7591 - val_loss: 2.3419 - val_accuracy: 0.4667\n",
      "Epoch 702/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6436 - accuracy: 0.7532 - val_loss: 2.3541 - val_accuracy: 0.4444\n",
      "Epoch 703/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5826 - accuracy: 0.7743 - val_loss: 2.3812 - val_accuracy: 0.4444\n",
      "Epoch 704/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6285 - accuracy: 0.7626 - val_loss: 2.3805 - val_accuracy: 0.4444\n",
      "Epoch 705/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5927 - accuracy: 0.7766 - val_loss: 2.3837 - val_accuracy: 0.4444\n",
      "Epoch 706/1000\n",
      "855/855 [==============================] - 0s 42us/step - loss: 0.6164 - accuracy: 0.7696 - val_loss: 2.3705 - val_accuracy: 0.4444\n",
      "Epoch 707/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5551 - accuracy: 0.7906 - val_loss: 2.3401 - val_accuracy: 0.4222\n",
      "Epoch 708/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5913 - accuracy: 0.7813 - val_loss: 2.3989 - val_accuracy: 0.4222\n",
      "Epoch 709/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6158 - accuracy: 0.7614 - val_loss: 2.4520 - val_accuracy: 0.4222\n",
      "Epoch 710/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.6095 - accuracy: 0.7801 - val_loss: 2.4525 - val_accuracy: 0.4222\n",
      "Epoch 711/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.6365 - accuracy: 0.7520 - val_loss: 2.4574 - val_accuracy: 0.4444\n",
      "Epoch 712/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6079 - accuracy: 0.7754 - val_loss: 2.4264 - val_accuracy: 0.4444\n",
      "Epoch 713/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6716 - accuracy: 0.7556 - val_loss: 2.3656 - val_accuracy: 0.4444\n",
      "Epoch 714/1000\n",
      "855/855 [==============================] - 0s 42us/step - loss: 0.6058 - accuracy: 0.7684 - val_loss: 2.3320 - val_accuracy: 0.4444\n",
      "Epoch 715/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6135 - accuracy: 0.7556 - val_loss: 2.3252 - val_accuracy: 0.4444\n",
      "Epoch 716/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6072 - accuracy: 0.7766 - val_loss: 2.3222 - val_accuracy: 0.4222\n",
      "Epoch 717/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.6526 - accuracy: 0.7579 - val_loss: 2.2814 - val_accuracy: 0.4444\n",
      "Epoch 718/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6532 - accuracy: 0.7626 - val_loss: 2.2937 - val_accuracy: 0.4444\n",
      "Epoch 719/1000\n",
      "855/855 [==============================] - 0s 49us/step - loss: 0.6134 - accuracy: 0.7637 - val_loss: 2.3040 - val_accuracy: 0.4444\n",
      "Epoch 720/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 0.6245 - accuracy: 0.7439 - val_loss: 2.2882 - val_accuracy: 0.4444\n",
      "Epoch 721/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6210 - accuracy: 0.7556 - val_loss: 2.2625 - val_accuracy: 0.4444\n",
      "Epoch 722/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6379 - accuracy: 0.7591 - val_loss: 2.2997 - val_accuracy: 0.4222\n",
      "Epoch 723/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.5951 - accuracy: 0.7719 - val_loss: 2.3901 - val_accuracy: 0.4667\n",
      "Epoch 724/1000\n",
      "855/855 [==============================] - 0s 42us/step - loss: 0.6337 - accuracy: 0.7614 - val_loss: 2.4033 - val_accuracy: 0.4667\n",
      "Epoch 725/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6245 - accuracy: 0.7708 - val_loss: 2.3921 - val_accuracy: 0.4444\n",
      "Epoch 726/1000\n",
      "855/855 [==============================] - 0s 55us/step - loss: 0.6085 - accuracy: 0.7731 - val_loss: 2.3524 - val_accuracy: 0.4444\n",
      "Epoch 727/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6581 - accuracy: 0.7532 - val_loss: 2.3876 - val_accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 728/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6020 - accuracy: 0.7731 - val_loss: 2.3595 - val_accuracy: 0.5111\n",
      "Epoch 729/1000\n",
      "855/855 [==============================] - 0s 42us/step - loss: 0.5875 - accuracy: 0.7813 - val_loss: 2.3838 - val_accuracy: 0.4667\n",
      "Epoch 730/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6365 - accuracy: 0.7474 - val_loss: 2.4696 - val_accuracy: 0.4667\n",
      "Epoch 731/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5846 - accuracy: 0.7871 - val_loss: 2.5142 - val_accuracy: 0.4222\n",
      "Epoch 732/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6211 - accuracy: 0.7602 - val_loss: 2.5160 - val_accuracy: 0.4222\n",
      "Epoch 733/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5906 - accuracy: 0.7895 - val_loss: 2.5034 - val_accuracy: 0.4222\n",
      "Epoch 734/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.6334 - accuracy: 0.7661 - val_loss: 2.4704 - val_accuracy: 0.4222\n",
      "Epoch 735/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.6069 - accuracy: 0.7591 - val_loss: 2.4553 - val_accuracy: 0.4667\n",
      "Epoch 736/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6357 - accuracy: 0.7509 - val_loss: 2.4289 - val_accuracy: 0.4667\n",
      "Epoch 737/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6148 - accuracy: 0.7813 - val_loss: 2.4433 - val_accuracy: 0.4444\n",
      "Epoch 738/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6191 - accuracy: 0.7579 - val_loss: 2.4377 - val_accuracy: 0.4667\n",
      "Epoch 739/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6697 - accuracy: 0.7567 - val_loss: 2.4497 - val_accuracy: 0.4444\n",
      "Epoch 740/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6113 - accuracy: 0.7673 - val_loss: 2.4321 - val_accuracy: 0.4444\n",
      "Epoch 741/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5858 - accuracy: 0.7719 - val_loss: 2.4225 - val_accuracy: 0.4667\n",
      "Epoch 742/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6048 - accuracy: 0.7789 - val_loss: 2.4052 - val_accuracy: 0.4444\n",
      "Epoch 743/1000\n",
      "855/855 [==============================] - 0s 42us/step - loss: 0.6290 - accuracy: 0.7801 - val_loss: 2.3974 - val_accuracy: 0.4444\n",
      "Epoch 744/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5934 - accuracy: 0.7883 - val_loss: 2.3807 - val_accuracy: 0.4444\n",
      "Epoch 745/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6321 - accuracy: 0.7497 - val_loss: 2.3727 - val_accuracy: 0.4444\n",
      "Epoch 746/1000\n",
      "855/855 [==============================] - 0s 42us/step - loss: 0.5854 - accuracy: 0.7591 - val_loss: 2.3554 - val_accuracy: 0.4444\n",
      "Epoch 747/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6253 - accuracy: 0.7731 - val_loss: 2.3718 - val_accuracy: 0.4444\n",
      "Epoch 748/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5553 - accuracy: 0.7743 - val_loss: 2.3961 - val_accuracy: 0.4444\n",
      "Epoch 749/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5606 - accuracy: 0.7906 - val_loss: 2.3702 - val_accuracy: 0.4444\n",
      "Epoch 750/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6401 - accuracy: 0.7462 - val_loss: 2.3658 - val_accuracy: 0.4222\n",
      "Epoch 751/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5841 - accuracy: 0.7801 - val_loss: 2.3275 - val_accuracy: 0.4222\n",
      "Epoch 752/1000\n",
      "855/855 [==============================] - 0s 42us/step - loss: 0.6280 - accuracy: 0.7626 - val_loss: 2.3467 - val_accuracy: 0.4222\n",
      "Epoch 753/1000\n",
      "855/855 [==============================] - 0s 54us/step - loss: 0.5701 - accuracy: 0.7789 - val_loss: 2.3483 - val_accuracy: 0.4444\n",
      "Epoch 754/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.6531 - accuracy: 0.7614 - val_loss: 2.3682 - val_accuracy: 0.4444\n",
      "Epoch 755/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6406 - accuracy: 0.7696 - val_loss: 2.3382 - val_accuracy: 0.4222\n",
      "Epoch 756/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6039 - accuracy: 0.7708 - val_loss: 2.2879 - val_accuracy: 0.4222\n",
      "Epoch 757/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6059 - accuracy: 0.7556 - val_loss: 2.2770 - val_accuracy: 0.4444\n",
      "Epoch 758/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6044 - accuracy: 0.7731 - val_loss: 2.2874 - val_accuracy: 0.4444\n",
      "Epoch 759/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5904 - accuracy: 0.7626 - val_loss: 2.3161 - val_accuracy: 0.4222\n",
      "Epoch 760/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6132 - accuracy: 0.7825 - val_loss: 2.3283 - val_accuracy: 0.4222\n",
      "Epoch 761/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5785 - accuracy: 0.7848 - val_loss: 2.3407 - val_accuracy: 0.4444\n",
      "Epoch 762/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5941 - accuracy: 0.7520 - val_loss: 2.3784 - val_accuracy: 0.4444\n",
      "Epoch 763/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6042 - accuracy: 0.7684 - val_loss: 2.3360 - val_accuracy: 0.4667\n",
      "Epoch 764/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.5468 - accuracy: 0.7977 - val_loss: 2.3074 - val_accuracy: 0.4667\n",
      "Epoch 765/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5920 - accuracy: 0.7673 - val_loss: 2.3562 - val_accuracy: 0.4889\n",
      "Epoch 766/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6396 - accuracy: 0.7696 - val_loss: 2.4223 - val_accuracy: 0.4889\n",
      "Epoch 767/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5877 - accuracy: 0.7789 - val_loss: 2.4157 - val_accuracy: 0.4667\n",
      "Epoch 768/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6100 - accuracy: 0.7719 - val_loss: 2.3762 - val_accuracy: 0.4667\n",
      "Epoch 769/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5362 - accuracy: 0.8012 - val_loss: 2.4021 - val_accuracy: 0.4889\n",
      "Epoch 770/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.5811 - accuracy: 0.7895 - val_loss: 2.4818 - val_accuracy: 0.4889\n",
      "Epoch 771/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6189 - accuracy: 0.7836 - val_loss: 2.5318 - val_accuracy: 0.4889\n",
      "Epoch 772/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.5956 - accuracy: 0.7719 - val_loss: 2.5547 - val_accuracy: 0.4444\n",
      "Epoch 773/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5574 - accuracy: 0.7918 - val_loss: 2.5132 - val_accuracy: 0.4444\n",
      "Epoch 774/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5691 - accuracy: 0.7602 - val_loss: 2.5249 - val_accuracy: 0.4444\n",
      "Epoch 775/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.6302 - accuracy: 0.7556 - val_loss: 2.5232 - val_accuracy: 0.4444\n",
      "Epoch 776/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6030 - accuracy: 0.7509 - val_loss: 2.5158 - val_accuracy: 0.4444\n",
      "Epoch 777/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.6368 - accuracy: 0.7439 - val_loss: 2.4973 - val_accuracy: 0.4444\n",
      "Epoch 778/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.5731 - accuracy: 0.7965 - val_loss: 2.5223 - val_accuracy: 0.4222\n",
      "Epoch 779/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6203 - accuracy: 0.7778 - val_loss: 2.5232 - val_accuracy: 0.4444\n",
      "Epoch 780/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 0.6224 - accuracy: 0.7567 - val_loss: 2.4175 - val_accuracy: 0.4222\n",
      "Epoch 781/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.6041 - accuracy: 0.7719 - val_loss: 2.3714 - val_accuracy: 0.4444\n",
      "Epoch 782/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.5561 - accuracy: 0.7918 - val_loss: 2.3610 - val_accuracy: 0.4222\n",
      "Epoch 783/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.6285 - accuracy: 0.7661 - val_loss: 2.3946 - val_accuracy: 0.4222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 784/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6487 - accuracy: 0.7579 - val_loss: 2.4479 - val_accuracy: 0.4444\n",
      "Epoch 785/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5663 - accuracy: 0.7906 - val_loss: 2.4756 - val_accuracy: 0.4667\n",
      "Epoch 786/1000\n",
      "855/855 [==============================] - 0s 42us/step - loss: 0.6050 - accuracy: 0.7696 - val_loss: 2.4626 - val_accuracy: 0.4667\n",
      "Epoch 787/1000\n",
      "855/855 [==============================] - 0s 59us/step - loss: 0.6297 - accuracy: 0.7626 - val_loss: 2.4088 - val_accuracy: 0.4667\n",
      "Epoch 788/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5907 - accuracy: 0.7848 - val_loss: 2.3955 - val_accuracy: 0.4667\n",
      "Epoch 789/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6042 - accuracy: 0.7696 - val_loss: 2.4346 - val_accuracy: 0.4667\n",
      "Epoch 790/1000\n",
      "855/855 [==============================] - 0s 42us/step - loss: 0.5922 - accuracy: 0.7649 - val_loss: 2.4693 - val_accuracy: 0.4667\n",
      "Epoch 791/1000\n",
      "855/855 [==============================] - 0s 42us/step - loss: 0.5733 - accuracy: 0.7813 - val_loss: 2.4698 - val_accuracy: 0.4667\n",
      "Epoch 792/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6042 - accuracy: 0.7579 - val_loss: 2.4547 - val_accuracy: 0.4667\n",
      "Epoch 793/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5935 - accuracy: 0.7871 - val_loss: 2.4266 - val_accuracy: 0.4444\n",
      "Epoch 794/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6248 - accuracy: 0.7673 - val_loss: 2.4641 - val_accuracy: 0.4444\n",
      "Epoch 795/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5886 - accuracy: 0.7836 - val_loss: 2.4662 - val_accuracy: 0.4667\n",
      "Epoch 796/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5810 - accuracy: 0.7860 - val_loss: 2.5052 - val_accuracy: 0.4889\n",
      "Epoch 797/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5896 - accuracy: 0.7754 - val_loss: 2.5034 - val_accuracy: 0.4889\n",
      "Epoch 798/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5571 - accuracy: 0.7789 - val_loss: 2.5089 - val_accuracy: 0.4889\n",
      "Epoch 799/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5959 - accuracy: 0.7743 - val_loss: 2.4907 - val_accuracy: 0.4889\n",
      "Epoch 800/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5488 - accuracy: 0.7895 - val_loss: 2.4829 - val_accuracy: 0.4444\n",
      "Epoch 801/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5921 - accuracy: 0.7754 - val_loss: 2.4789 - val_accuracy: 0.4667\n",
      "Epoch 802/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5818 - accuracy: 0.7708 - val_loss: 2.5025 - val_accuracy: 0.4667\n",
      "Epoch 803/1000\n",
      "855/855 [==============================] - 0s 42us/step - loss: 0.6155 - accuracy: 0.7509 - val_loss: 2.5275 - val_accuracy: 0.4667\n",
      "Epoch 804/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5535 - accuracy: 0.7883 - val_loss: 2.5184 - val_accuracy: 0.4444\n",
      "Epoch 805/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5952 - accuracy: 0.7778 - val_loss: 2.5250 - val_accuracy: 0.4444\n",
      "Epoch 806/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6090 - accuracy: 0.7684 - val_loss: 2.5440 - val_accuracy: 0.4444\n",
      "Epoch 807/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6000 - accuracy: 0.7673 - val_loss: 2.5120 - val_accuracy: 0.4444\n",
      "Epoch 808/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6121 - accuracy: 0.7649 - val_loss: 2.4987 - val_accuracy: 0.4667\n",
      "Epoch 809/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5715 - accuracy: 0.7778 - val_loss: 2.5128 - val_accuracy: 0.4444\n",
      "Epoch 810/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6105 - accuracy: 0.7860 - val_loss: 2.5175 - val_accuracy: 0.4444\n",
      "Epoch 811/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6243 - accuracy: 0.7509 - val_loss: 2.4983 - val_accuracy: 0.4889\n",
      "Epoch 812/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.5659 - accuracy: 0.7801 - val_loss: 2.5430 - val_accuracy: 0.4889\n",
      "Epoch 813/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5843 - accuracy: 0.7673 - val_loss: 2.5260 - val_accuracy: 0.4667\n",
      "Epoch 814/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6147 - accuracy: 0.7649 - val_loss: 2.4796 - val_accuracy: 0.4444\n",
      "Epoch 815/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5900 - accuracy: 0.7567 - val_loss: 2.4152 - val_accuracy: 0.4444\n",
      "Epoch 816/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5584 - accuracy: 0.7813 - val_loss: 2.4154 - val_accuracy: 0.4667\n",
      "Epoch 817/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.5767 - accuracy: 0.7860 - val_loss: 2.4398 - val_accuracy: 0.4667\n",
      "Epoch 818/1000\n",
      "855/855 [==============================] - 0s 50us/step - loss: 0.6087 - accuracy: 0.7696 - val_loss: 2.4233 - val_accuracy: 0.4667\n",
      "Epoch 819/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6283 - accuracy: 0.7743 - val_loss: 2.4093 - val_accuracy: 0.4444\n",
      "Epoch 820/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5698 - accuracy: 0.7813 - val_loss: 2.4253 - val_accuracy: 0.4444\n",
      "Epoch 821/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6111 - accuracy: 0.7754 - val_loss: 2.4010 - val_accuracy: 0.5111\n",
      "Epoch 822/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6240 - accuracy: 0.7661 - val_loss: 2.3806 - val_accuracy: 0.4667\n",
      "Epoch 823/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6142 - accuracy: 0.7661 - val_loss: 2.3900 - val_accuracy: 0.4444\n",
      "Epoch 824/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5899 - accuracy: 0.7684 - val_loss: 2.4452 - val_accuracy: 0.4667\n",
      "Epoch 825/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5938 - accuracy: 0.7602 - val_loss: 2.4787 - val_accuracy: 0.4667\n",
      "Epoch 826/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.5974 - accuracy: 0.7649 - val_loss: 2.4875 - val_accuracy: 0.4667\n",
      "Epoch 827/1000\n",
      "855/855 [==============================] - 0s 42us/step - loss: 0.6429 - accuracy: 0.7602 - val_loss: 2.4461 - val_accuracy: 0.4444\n",
      "Epoch 828/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5983 - accuracy: 0.7789 - val_loss: 2.4621 - val_accuracy: 0.4444\n",
      "Epoch 829/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5553 - accuracy: 0.7860 - val_loss: 2.5387 - val_accuracy: 0.4444\n",
      "Epoch 830/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6165 - accuracy: 0.7918 - val_loss: 2.5194 - val_accuracy: 0.4444\n",
      "Epoch 831/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5657 - accuracy: 0.7930 - val_loss: 2.4924 - val_accuracy: 0.4222\n",
      "Epoch 832/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6118 - accuracy: 0.7626 - val_loss: 2.4341 - val_accuracy: 0.4222\n",
      "Epoch 833/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5883 - accuracy: 0.7708 - val_loss: 2.4083 - val_accuracy: 0.4222\n",
      "Epoch 834/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5864 - accuracy: 0.7708 - val_loss: 2.3966 - val_accuracy: 0.4222\n",
      "Epoch 835/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.5552 - accuracy: 0.7836 - val_loss: 2.3986 - val_accuracy: 0.4444\n",
      "Epoch 836/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5762 - accuracy: 0.7836 - val_loss: 2.4331 - val_accuracy: 0.4444\n",
      "Epoch 837/1000\n",
      "855/855 [==============================] - 0s 42us/step - loss: 0.5224 - accuracy: 0.8023 - val_loss: 2.4723 - val_accuracy: 0.4444\n",
      "Epoch 838/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.5786 - accuracy: 0.7871 - val_loss: 2.4912 - val_accuracy: 0.4444\n",
      "Epoch 839/1000\n",
      "855/855 [==============================] - 0s 42us/step - loss: 0.5918 - accuracy: 0.7848 - val_loss: 2.4379 - val_accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 840/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5647 - accuracy: 0.7719 - val_loss: 2.3991 - val_accuracy: 0.4444\n",
      "Epoch 841/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5740 - accuracy: 0.7848 - val_loss: 2.4301 - val_accuracy: 0.4444\n",
      "Epoch 842/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5935 - accuracy: 0.7684 - val_loss: 2.4259 - val_accuracy: 0.4444\n",
      "Epoch 843/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5796 - accuracy: 0.7836 - val_loss: 2.4076 - val_accuracy: 0.4667\n",
      "Epoch 844/1000\n",
      "855/855 [==============================] - 0s 51us/step - loss: 0.5720 - accuracy: 0.7906 - val_loss: 2.3638 - val_accuracy: 0.4667\n",
      "Epoch 845/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.6023 - accuracy: 0.7684 - val_loss: 2.3343 - val_accuracy: 0.4444\n",
      "Epoch 846/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.5954 - accuracy: 0.7801 - val_loss: 2.3303 - val_accuracy: 0.4444\n",
      "Epoch 847/1000\n",
      "855/855 [==============================] - 0s 54us/step - loss: 0.5891 - accuracy: 0.7743 - val_loss: 2.3859 - val_accuracy: 0.4222\n",
      "Epoch 848/1000\n",
      "855/855 [==============================] - 0s 55us/step - loss: 0.6025 - accuracy: 0.7614 - val_loss: 2.3930 - val_accuracy: 0.4222\n",
      "Epoch 849/1000\n",
      "855/855 [==============================] - 0s 55us/step - loss: 0.5265 - accuracy: 0.8035 - val_loss: 2.4073 - val_accuracy: 0.4444\n",
      "Epoch 850/1000\n",
      "855/855 [==============================] - 0s 55us/step - loss: 0.5892 - accuracy: 0.7673 - val_loss: 2.4036 - val_accuracy: 0.4667\n",
      "Epoch 851/1000\n",
      "855/855 [==============================] - 0s 52us/step - loss: 0.6163 - accuracy: 0.7766 - val_loss: 2.4386 - val_accuracy: 0.4889\n",
      "Epoch 852/1000\n",
      "855/855 [==============================] - 0s 49us/step - loss: 0.5871 - accuracy: 0.7673 - val_loss: 2.4683 - val_accuracy: 0.4889\n",
      "Epoch 853/1000\n",
      "855/855 [==============================] - 0s 50us/step - loss: 0.5697 - accuracy: 0.7813 - val_loss: 2.4520 - val_accuracy: 0.5111\n",
      "Epoch 854/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 0.5620 - accuracy: 0.7778 - val_loss: 2.4907 - val_accuracy: 0.4889\n",
      "Epoch 855/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.5794 - accuracy: 0.7813 - val_loss: 2.5222 - val_accuracy: 0.4444\n",
      "Epoch 856/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.5742 - accuracy: 0.7789 - val_loss: 2.5324 - val_accuracy: 0.4444\n",
      "Epoch 857/1000\n",
      "855/855 [==============================] - 0s 49us/step - loss: 0.5755 - accuracy: 0.7801 - val_loss: 2.5392 - val_accuracy: 0.4667\n",
      "Epoch 858/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.5824 - accuracy: 0.7942 - val_loss: 2.5089 - val_accuracy: 0.4667\n",
      "Epoch 859/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6034 - accuracy: 0.7906 - val_loss: 2.4767 - val_accuracy: 0.4667\n",
      "Epoch 860/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 0.6184 - accuracy: 0.7684 - val_loss: 2.4400 - val_accuracy: 0.4667\n",
      "Epoch 861/1000\n",
      "855/855 [==============================] - 0s 50us/step - loss: 0.5486 - accuracy: 0.7871 - val_loss: 2.3701 - val_accuracy: 0.4444\n",
      "Epoch 862/1000\n",
      "855/855 [==============================] - 0s 50us/step - loss: 0.5573 - accuracy: 0.7953 - val_loss: 2.3952 - val_accuracy: 0.4444\n",
      "Epoch 863/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.5535 - accuracy: 0.8047 - val_loss: 2.4550 - val_accuracy: 0.4222\n",
      "Epoch 864/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.5851 - accuracy: 0.7696 - val_loss: 2.4372 - val_accuracy: 0.4667\n",
      "Epoch 865/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.5762 - accuracy: 0.7848 - val_loss: 2.4420 - val_accuracy: 0.4667\n",
      "Epoch 866/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 0.5634 - accuracy: 0.7789 - val_loss: 2.4373 - val_accuracy: 0.4667\n",
      "Epoch 867/1000\n",
      "855/855 [==============================] - 0s 49us/step - loss: 0.5382 - accuracy: 0.8000 - val_loss: 2.4559 - val_accuracy: 0.4444\n",
      "Epoch 868/1000\n",
      "855/855 [==============================] - 0s 50us/step - loss: 0.6199 - accuracy: 0.7673 - val_loss: 2.4477 - val_accuracy: 0.4444\n",
      "Epoch 869/1000\n",
      "855/855 [==============================] - 0s 51us/step - loss: 0.5778 - accuracy: 0.7813 - val_loss: 2.4209 - val_accuracy: 0.4222\n",
      "Epoch 870/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 0.5678 - accuracy: 0.7988 - val_loss: 2.3547 - val_accuracy: 0.4444\n",
      "Epoch 871/1000\n",
      "855/855 [==============================] - 0s 49us/step - loss: 0.5531 - accuracy: 0.7708 - val_loss: 2.3424 - val_accuracy: 0.4667\n",
      "Epoch 872/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.5656 - accuracy: 0.7883 - val_loss: 2.3831 - val_accuracy: 0.4444\n",
      "Epoch 873/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5787 - accuracy: 0.7731 - val_loss: 2.3992 - val_accuracy: 0.4889\n",
      "Epoch 874/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6032 - accuracy: 0.7789 - val_loss: 2.4258 - val_accuracy: 0.4889\n",
      "Epoch 875/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5535 - accuracy: 0.7883 - val_loss: 2.3894 - val_accuracy: 0.4667\n",
      "Epoch 876/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.6130 - accuracy: 0.7661 - val_loss: 2.3674 - val_accuracy: 0.4444\n",
      "Epoch 877/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5538 - accuracy: 0.7930 - val_loss: 2.4425 - val_accuracy: 0.4444\n",
      "Epoch 878/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5546 - accuracy: 0.7860 - val_loss: 2.4924 - val_accuracy: 0.4222\n",
      "Epoch 879/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5707 - accuracy: 0.7708 - val_loss: 2.5278 - val_accuracy: 0.4667\n",
      "Epoch 880/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6045 - accuracy: 0.7848 - val_loss: 2.5440 - val_accuracy: 0.4444\n",
      "Epoch 881/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5925 - accuracy: 0.7778 - val_loss: 2.5280 - val_accuracy: 0.4444\n",
      "Epoch 882/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.5706 - accuracy: 0.7778 - val_loss: 2.5320 - val_accuracy: 0.4444\n",
      "Epoch 883/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5895 - accuracy: 0.7825 - val_loss: 2.5287 - val_accuracy: 0.4444\n",
      "Epoch 884/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5566 - accuracy: 0.7789 - val_loss: 2.4659 - val_accuracy: 0.4444\n",
      "Epoch 885/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5570 - accuracy: 0.7860 - val_loss: 2.4595 - val_accuracy: 0.4444\n",
      "Epoch 886/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5658 - accuracy: 0.7930 - val_loss: 2.4559 - val_accuracy: 0.4667\n",
      "Epoch 887/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5803 - accuracy: 0.7836 - val_loss: 2.4326 - val_accuracy: 0.4222\n",
      "Epoch 888/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5501 - accuracy: 0.7836 - val_loss: 2.4330 - val_accuracy: 0.4667\n",
      "Epoch 889/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5604 - accuracy: 0.7918 - val_loss: 2.4831 - val_accuracy: 0.4444\n",
      "Epoch 890/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6224 - accuracy: 0.7556 - val_loss: 2.5096 - val_accuracy: 0.4667\n",
      "Epoch 891/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5723 - accuracy: 0.7789 - val_loss: 2.4995 - val_accuracy: 0.4444\n",
      "Epoch 892/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.5780 - accuracy: 0.7918 - val_loss: 2.4677 - val_accuracy: 0.5111\n",
      "Epoch 893/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5643 - accuracy: 0.7836 - val_loss: 2.4037 - val_accuracy: 0.4889\n",
      "Epoch 894/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5741 - accuracy: 0.7848 - val_loss: 2.3274 - val_accuracy: 0.4667\n",
      "Epoch 895/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6029 - accuracy: 0.7801 - val_loss: 2.3240 - val_accuracy: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 896/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5991 - accuracy: 0.7836 - val_loss: 2.3569 - val_accuracy: 0.4444\n",
      "Epoch 897/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5732 - accuracy: 0.7778 - val_loss: 2.3578 - val_accuracy: 0.4667\n",
      "Epoch 898/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5425 - accuracy: 0.7871 - val_loss: 2.3885 - val_accuracy: 0.4667\n",
      "Epoch 899/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5565 - accuracy: 0.7825 - val_loss: 2.4273 - val_accuracy: 0.4889\n",
      "Epoch 900/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.5536 - accuracy: 0.7848 - val_loss: 2.4104 - val_accuracy: 0.4667\n",
      "Epoch 901/1000\n",
      "855/855 [==============================] - 0s 51us/step - loss: 0.5564 - accuracy: 0.7836 - val_loss: 2.4235 - val_accuracy: 0.4889\n",
      "Epoch 902/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5441 - accuracy: 0.8035 - val_loss: 2.4623 - val_accuracy: 0.4889\n",
      "Epoch 903/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5840 - accuracy: 0.7813 - val_loss: 2.4845 - val_accuracy: 0.4889\n",
      "Epoch 904/1000\n",
      "855/855 [==============================] - 0s 42us/step - loss: 0.5892 - accuracy: 0.7965 - val_loss: 2.4450 - val_accuracy: 0.4667\n",
      "Epoch 905/1000\n",
      "855/855 [==============================] - 0s 42us/step - loss: 0.5768 - accuracy: 0.7848 - val_loss: 2.4147 - val_accuracy: 0.4667\n",
      "Epoch 906/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5524 - accuracy: 0.7825 - val_loss: 2.4509 - val_accuracy: 0.4667\n",
      "Epoch 907/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5498 - accuracy: 0.7895 - val_loss: 2.4740 - val_accuracy: 0.4667\n",
      "Epoch 908/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5732 - accuracy: 0.7825 - val_loss: 2.5156 - val_accuracy: 0.4667\n",
      "Epoch 909/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5637 - accuracy: 0.7825 - val_loss: 2.5400 - val_accuracy: 0.4667\n",
      "Epoch 910/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5511 - accuracy: 0.8035 - val_loss: 2.5135 - val_accuracy: 0.4444\n",
      "Epoch 911/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5637 - accuracy: 0.7953 - val_loss: 2.5167 - val_accuracy: 0.4444\n",
      "Epoch 912/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5549 - accuracy: 0.7848 - val_loss: 2.5474 - val_accuracy: 0.4667\n",
      "Epoch 913/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5336 - accuracy: 0.7895 - val_loss: 2.5567 - val_accuracy: 0.4444\n",
      "Epoch 914/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5592 - accuracy: 0.7871 - val_loss: 2.5393 - val_accuracy: 0.4667\n",
      "Epoch 915/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5914 - accuracy: 0.7801 - val_loss: 2.5163 - val_accuracy: 0.4667\n",
      "Epoch 916/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5797 - accuracy: 0.7930 - val_loss: 2.5113 - val_accuracy: 0.4667\n",
      "Epoch 917/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 0.5642 - accuracy: 0.7766 - val_loss: 2.5314 - val_accuracy: 0.4889\n",
      "Epoch 918/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5766 - accuracy: 0.7801 - val_loss: 2.5311 - val_accuracy: 0.5111\n",
      "Epoch 919/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5941 - accuracy: 0.7719 - val_loss: 2.4924 - val_accuracy: 0.4667\n",
      "Epoch 920/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.5465 - accuracy: 0.7977 - val_loss: 2.5467 - val_accuracy: 0.4667\n",
      "Epoch 921/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5860 - accuracy: 0.7918 - val_loss: 2.5512 - val_accuracy: 0.4667\n",
      "Epoch 922/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.5563 - accuracy: 0.7977 - val_loss: 2.5421 - val_accuracy: 0.4889\n",
      "Epoch 923/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.5503 - accuracy: 0.7883 - val_loss: 2.4843 - val_accuracy: 0.4889\n",
      "Epoch 924/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.5445 - accuracy: 0.8023 - val_loss: 2.4568 - val_accuracy: 0.4889\n",
      "Epoch 925/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.5740 - accuracy: 0.7848 - val_loss: 2.4380 - val_accuracy: 0.5111\n",
      "Epoch 926/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5955 - accuracy: 0.7719 - val_loss: 2.4186 - val_accuracy: 0.4889\n",
      "Epoch 927/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5645 - accuracy: 0.7731 - val_loss: 2.3600 - val_accuracy: 0.4444\n",
      "Epoch 928/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5651 - accuracy: 0.7836 - val_loss: 2.4000 - val_accuracy: 0.4444\n",
      "Epoch 929/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5402 - accuracy: 0.7977 - val_loss: 2.4570 - val_accuracy: 0.5111\n",
      "Epoch 930/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5384 - accuracy: 0.8047 - val_loss: 2.4854 - val_accuracy: 0.5111\n",
      "Epoch 931/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.5804 - accuracy: 0.7836 - val_loss: 2.5071 - val_accuracy: 0.4889\n",
      "Epoch 932/1000\n",
      "855/855 [==============================] - 0s 50us/step - loss: 0.5351 - accuracy: 0.7871 - val_loss: 2.5161 - val_accuracy: 0.4889\n",
      "Epoch 933/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.5754 - accuracy: 0.7860 - val_loss: 2.5293 - val_accuracy: 0.4889\n",
      "Epoch 934/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5464 - accuracy: 0.7918 - val_loss: 2.5259 - val_accuracy: 0.4889\n",
      "Epoch 935/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.5486 - accuracy: 0.7789 - val_loss: 2.4967 - val_accuracy: 0.4889\n",
      "Epoch 936/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5420 - accuracy: 0.7883 - val_loss: 2.4846 - val_accuracy: 0.4889\n",
      "Epoch 937/1000\n",
      "855/855 [==============================] - 0s 42us/step - loss: 0.5303 - accuracy: 0.8047 - val_loss: 2.5321 - val_accuracy: 0.4889\n",
      "Epoch 938/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5582 - accuracy: 0.7871 - val_loss: 2.5602 - val_accuracy: 0.4667\n",
      "Epoch 939/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5141 - accuracy: 0.8070 - val_loss: 2.5652 - val_accuracy: 0.4667\n",
      "Epoch 940/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6025 - accuracy: 0.7766 - val_loss: 2.4993 - val_accuracy: 0.4667\n",
      "Epoch 941/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5769 - accuracy: 0.7778 - val_loss: 2.4291 - val_accuracy: 0.5111\n",
      "Epoch 942/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5917 - accuracy: 0.7778 - val_loss: 2.4462 - val_accuracy: 0.4667\n",
      "Epoch 943/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5659 - accuracy: 0.7977 - val_loss: 2.5196 - val_accuracy: 0.4667\n",
      "Epoch 944/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.4985 - accuracy: 0.8070 - val_loss: 2.5439 - val_accuracy: 0.4667\n",
      "Epoch 945/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.6233 - accuracy: 0.7649 - val_loss: 2.5620 - val_accuracy: 0.4444\n",
      "Epoch 946/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5413 - accuracy: 0.7953 - val_loss: 2.5706 - val_accuracy: 0.4667\n",
      "Epoch 947/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5650 - accuracy: 0.7988 - val_loss: 2.5779 - val_accuracy: 0.4889\n",
      "Epoch 948/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5702 - accuracy: 0.7906 - val_loss: 2.5642 - val_accuracy: 0.5111\n",
      "Epoch 949/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5890 - accuracy: 0.7953 - val_loss: 2.5767 - val_accuracy: 0.4889\n",
      "Epoch 950/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5704 - accuracy: 0.7918 - val_loss: 2.5487 - val_accuracy: 0.4889\n",
      "Epoch 951/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5293 - accuracy: 0.7988 - val_loss: 2.4832 - val_accuracy: 0.5111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 952/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5428 - accuracy: 0.7825 - val_loss: 2.4231 - val_accuracy: 0.5111\n",
      "Epoch 953/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.5240 - accuracy: 0.7988 - val_loss: 2.3952 - val_accuracy: 0.5111\n",
      "Epoch 954/1000\n",
      "855/855 [==============================] - 0s 42us/step - loss: 0.5563 - accuracy: 0.8035 - val_loss: 2.4209 - val_accuracy: 0.5111\n",
      "Epoch 955/1000\n",
      "855/855 [==============================] - 0s 42us/step - loss: 0.5491 - accuracy: 0.7906 - val_loss: 2.4469 - val_accuracy: 0.4889\n",
      "Epoch 956/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5215 - accuracy: 0.8000 - val_loss: 2.4360 - val_accuracy: 0.4889\n",
      "Epoch 957/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5421 - accuracy: 0.8035 - val_loss: 2.4070 - val_accuracy: 0.4889\n",
      "Epoch 958/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5781 - accuracy: 0.7883 - val_loss: 2.4023 - val_accuracy: 0.4889\n",
      "Epoch 959/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.4858 - accuracy: 0.8047 - val_loss: 2.4560 - val_accuracy: 0.4889\n",
      "Epoch 960/1000\n",
      "855/855 [==============================] - 0s 42us/step - loss: 0.5209 - accuracy: 0.8035 - val_loss: 2.4819 - val_accuracy: 0.4889\n",
      "Epoch 961/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5529 - accuracy: 0.7848 - val_loss: 2.4640 - val_accuracy: 0.4889\n",
      "Epoch 962/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5308 - accuracy: 0.7977 - val_loss: 2.4712 - val_accuracy: 0.4889\n",
      "Epoch 963/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5429 - accuracy: 0.7906 - val_loss: 2.4773 - val_accuracy: 0.4667\n",
      "Epoch 964/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5488 - accuracy: 0.7895 - val_loss: 2.4377 - val_accuracy: 0.4667\n",
      "Epoch 965/1000\n",
      "855/855 [==============================] - 0s 42us/step - loss: 0.5442 - accuracy: 0.7895 - val_loss: 2.4247 - val_accuracy: 0.4667\n",
      "Epoch 966/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5559 - accuracy: 0.7988 - val_loss: 2.4222 - val_accuracy: 0.4667\n",
      "Epoch 967/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.6034 - accuracy: 0.7696 - val_loss: 2.4626 - val_accuracy: 0.4889\n",
      "Epoch 968/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5852 - accuracy: 0.7719 - val_loss: 2.4899 - val_accuracy: 0.4667\n",
      "Epoch 969/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.4897 - accuracy: 0.8234 - val_loss: 2.4921 - val_accuracy: 0.4889\n",
      "Epoch 970/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5649 - accuracy: 0.7860 - val_loss: 2.4597 - val_accuracy: 0.4889\n",
      "Epoch 971/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5096 - accuracy: 0.7953 - val_loss: 2.4663 - val_accuracy: 0.4667\n",
      "Epoch 972/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5583 - accuracy: 0.7754 - val_loss: 2.5380 - val_accuracy: 0.4667\n",
      "Epoch 973/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5202 - accuracy: 0.8140 - val_loss: 2.6247 - val_accuracy: 0.4889\n",
      "Epoch 974/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5471 - accuracy: 0.7848 - val_loss: 2.6545 - val_accuracy: 0.5111\n",
      "Epoch 975/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5918 - accuracy: 0.7708 - val_loss: 2.6114 - val_accuracy: 0.5111\n",
      "Epoch 976/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.5556 - accuracy: 0.7871 - val_loss: 2.5405 - val_accuracy: 0.4889\n",
      "Epoch 977/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5665 - accuracy: 0.7918 - val_loss: 2.5323 - val_accuracy: 0.4889\n",
      "Epoch 978/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5629 - accuracy: 0.7895 - val_loss: 2.5127 - val_accuracy: 0.4667\n",
      "Epoch 979/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5730 - accuracy: 0.8000 - val_loss: 2.4974 - val_accuracy: 0.5111\n",
      "Epoch 980/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5632 - accuracy: 0.7860 - val_loss: 2.5204 - val_accuracy: 0.5333\n",
      "Epoch 981/1000\n",
      "855/855 [==============================] - 0s 52us/step - loss: 0.5634 - accuracy: 0.7906 - val_loss: 2.5217 - val_accuracy: 0.5111\n",
      "Epoch 982/1000\n",
      "855/855 [==============================] - 0s 42us/step - loss: 0.5440 - accuracy: 0.8047 - val_loss: 2.5043 - val_accuracy: 0.4889\n",
      "Epoch 983/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5495 - accuracy: 0.7895 - val_loss: 2.4823 - val_accuracy: 0.4889\n",
      "Epoch 984/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5466 - accuracy: 0.7813 - val_loss: 2.5129 - val_accuracy: 0.4889\n",
      "Epoch 985/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5542 - accuracy: 0.7895 - val_loss: 2.5340 - val_accuracy: 0.4889\n",
      "Epoch 986/1000\n",
      "855/855 [==============================] - 0s 42us/step - loss: 0.5454 - accuracy: 0.7977 - val_loss: 2.5404 - val_accuracy: 0.4889\n",
      "Epoch 987/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5360 - accuracy: 0.7930 - val_loss: 2.5344 - val_accuracy: 0.4667\n",
      "Epoch 988/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5459 - accuracy: 0.7766 - val_loss: 2.5338 - val_accuracy: 0.4444\n",
      "Epoch 989/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 0.5450 - accuracy: 0.7918 - val_loss: 2.5441 - val_accuracy: 0.4444\n",
      "Epoch 990/1000\n",
      "855/855 [==============================] - 0s 45us/step - loss: 0.5276 - accuracy: 0.8012 - val_loss: 2.5605 - val_accuracy: 0.4889\n",
      "Epoch 991/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5746 - accuracy: 0.7778 - val_loss: 2.5704 - val_accuracy: 0.4667\n",
      "Epoch 992/1000\n",
      "855/855 [==============================] - 0s 47us/step - loss: 0.5548 - accuracy: 0.8035 - val_loss: 2.5764 - val_accuracy: 0.4444\n",
      "Epoch 993/1000\n",
      "855/855 [==============================] - 0s 52us/step - loss: 0.5472 - accuracy: 0.8058 - val_loss: 2.5996 - val_accuracy: 0.4667\n",
      "Epoch 994/1000\n",
      "855/855 [==============================] - 0s 48us/step - loss: 0.5467 - accuracy: 0.7813 - val_loss: 2.6269 - val_accuracy: 0.4667\n",
      "Epoch 995/1000\n",
      "855/855 [==============================] - 0s 42us/step - loss: 0.5764 - accuracy: 0.7860 - val_loss: 2.5832 - val_accuracy: 0.4667\n",
      "Epoch 996/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5273 - accuracy: 0.8012 - val_loss: 2.5611 - val_accuracy: 0.4889\n",
      "Epoch 997/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5542 - accuracy: 0.7953 - val_loss: 2.5957 - val_accuracy: 0.5111\n",
      "Epoch 998/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5758 - accuracy: 0.7895 - val_loss: 2.6068 - val_accuracy: 0.5111\n",
      "Epoch 999/1000\n",
      "855/855 [==============================] - 0s 43us/step - loss: 0.5273 - accuracy: 0.7953 - val_loss: 2.6067 - val_accuracy: 0.4889\n",
      "Epoch 1000/1000\n",
      "855/855 [==============================] - 0s 44us/step - loss: 0.5330 - accuracy: 0.7848 - val_loss: 2.6029 - val_accuracy: 0.4667\n"
     ]
    }
   ],
   "source": [
    "music_model_train_dropout = music_model.fit(train_X, train_label, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_label))\n",
    "\n",
    "# music_train = music_model.fit(train_X, train_label, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_label))\n",
    "# music_train = music_model.fit(X_train, Y_train, validation_data=(X_test, Y_test) ,epochs=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_model.save(\"music_model_dropout.h5py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eval = music_model.evaluate(X_test, test_Y_one_hot, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 2.9270040512084963\n",
      "Test accuracy: 0.4000000059604645\n"
     ]
    }
   ],
   "source": [
    "print('Test loss:', test_eval[0])\n",
    "print('Test accuracy:', test_eval[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'music_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-89-8e6f40d03a49>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmusic_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mval_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmusic_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmusic_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmusic_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'music_train' is not defined"
     ]
    }
   ],
   "source": [
    "accuracy = music_train.history['accuracy']\n",
    "val_accuracy = music_train.history['val_accuracy']\n",
    "loss = music_train.history['loss']\n",
    "val_loss = music_train.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy = music_model_train_dropout.history['accuracy']\n",
    "val_accuracy = music_model_train_dropout.history['val_accuracy']\n",
    "loss = music_model_train_dropout.history['loss']\n",
    "val_loss = music_model_train_dropout.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = music_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = np.argmax(np.round(predicted_classes),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100,), (100,))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_classes.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29 correct labels\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 2 into shape (29,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-94-e8bd9ae771fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m29\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gray'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'none'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Predicted {}, Class {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted_classes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 2 into shape (29,1)"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAI8AAABjCAYAAACi5VNqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAE5klEQVR4nO3dT4gWdRzH8fcnzQIPCekhSjBJWjx00IfwFEEE6kEPddCLGcYiJZ2DDoGX6BRIkWwkZQeTPG1QBFHgSfNZKNOiWINoSXCt8BJYwrfDDLZujzuzX2d8Zh8/L3jgmWf+PN8f+2GeZ2b2+Y4iArOMu4ZdgC1dDo+lOTyW5vBYmsNjaQ6PpVWGR9IRSZcknbvJfEk6JGla0llJm5ov07qozp7nfWDrAvO3ARvKxzjwzq2XZUtBZXgi4iTwxwKL7ASORuEUsErSA00VaN3VxHeeB4Ff50zPlK/ZiFvewDY04LWB1zwkjVN8tLFy5crNY2NjDby93aqpqanLEbFmses1EZ4ZYO2c6YeA3wYtGBETwARAr9eLfr/fwNvbrZL0S2a9Jj62JoE95VHXFuBKRFxsYLvWcZV7HknHgCeB1ZJmgNeAuwEi4jDwKbAdmAb+Ap5vq1jrlsrwRMTuivkBvNRYRbZk+AyzpTk8lubwWJrDY2kOj6U5PJbm8Fiaw2NpDo+lOTyW5vBYmsNjaQ6PpTk8lubwWJrDY2kOj6U5PJbm8Fiaw2NpDo+lOTyW5vBYWq3wSNoq6ceyB88rA+bvlTQr6Zvy8ULzpVrX1PnF6DLgbeBpit+ln5E0GRHfz1v0eEQcaKFG66g6e57HgemI+Dki/gY+oujJY3e4OuGp23/nmbKt3AlJawfMtxFTJzx1+u98AqyLiMeAL4APBm5IGpfUl9SfnZ1dXKXWOXXCU9l/JyJ+j4ir5eS7wOZBG4qIiYjoRURvzZpF9xKyjqkTnjPABkkPS1oB7KLoyXPdvB6EO4AfmivRuqpOi5Vrkg4AnwPLgCMRcV7SQaAfEZPAy5J2ANcoml/ubbFm6wgN65ZJbivXHZKmIqK32PV8htnSHB5Lc3gszeGxNIfH0hweS3N4LM3hsTSHx9IcHktzeCzN4bE0h8fSHB5Lc3gszeGxNIfH0hweS3N4LM3hsTSHx9IcHktzeCytqf4890g6Xs4/LWld04Va91SGZ05/nm3ARmC3pI3zFtsH/BkRjwBvAm80Xah1T1P9eXbyX2eME8BTkgZ117AR0lR/nuvLRMQ14ApwfxMFWndVNjqgXn+eOssgaRwYLyevSjpX4/27bDVwedhFNODRzEp1wlPZn2fOMjOSlgP3UXTLuEFETAATAJL6mR/Xd8kojAGKcWTWa6Q/Tzn9XPn8WeDLGFb7DbttmurP8x7woaRpij3OrjaLtm4YWn8eSePlx9iSNQpjgPw4hhYeW/p8ecLSWg/PKFzaGIXbJ0g6IunSzU6PqHCoHONZSZsqNxoRrT0ovmBfANYDK4BvgY3zlnkROFw+30VxG4JW62phDHuBt4Zda8U4ngA2AeduMn878BnFObstwOmqbba95xmFSxsjcfuEiDjJgHNvc+wEjkbhFLBqXovk/2k7PKNwaeNOuX1C3XFe13Z4Gru0MUSN3T6h4xb9d2g7PIu5tMFClzaGqLHbJ3Rcnb/VDdoOzyhc2rhTbp8wCewpj7q2AFci4uKCa9yGb/nbgZ8ojlheLV87COwon98LfAxMA18D64d9ZJIYw+vAeYojsa+AsWHXPGAMx4CLwD8Ue5l9wH5gfzlfFP/0dwH4DuhVbdNnmC3NZ5gtzeGxNIfH0hweS3N4LM3hsTSHx9IcHkv7FyqzOWDK9CHBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "correct = np.where(predicted_classes==Y_test)[0]\n",
    "print (\"Found %d correct labels\" % len(correct))\n",
    "for i, correct in enumerate(correct[:9]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(X_test[correct].reshape(29,1), cmap='gray', interpolation='none')\n",
    "    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[correct], Y_test[correct]))\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 71 incorrect labels\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 2 into shape (29,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-95-b6c6e3c2ac0b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincorrect\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mincorrect\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mincorrect\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m29\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gray'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'none'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Predicted {}, Class {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted_classes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mincorrect\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mincorrect\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 2 into shape (29,1)"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAI8AAABjCAYAAACi5VNqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAE5klEQVR4nO3dT4gWdRzH8fcnzQIPCekhSjBJWjx00IfwFEEE6kEPddCLGcYiJZ2DDoGX6BRIkWwkZQeTPG1QBFHgSfNZKNOiWINoSXCt8BJYwrfDDLZujzuzX2d8Zh8/L3jgmWf+PN8f+2GeZ2b2+Y4iArOMu4ZdgC1dDo+lOTyW5vBYmsNjaQ6PpVWGR9IRSZcknbvJfEk6JGla0llJm5ov07qozp7nfWDrAvO3ARvKxzjwzq2XZUtBZXgi4iTwxwKL7ASORuEUsErSA00VaN3VxHeeB4Ff50zPlK/ZiFvewDY04LWB1zwkjVN8tLFy5crNY2NjDby93aqpqanLEbFmses1EZ4ZYO2c6YeA3wYtGBETwARAr9eLfr/fwNvbrZL0S2a9Jj62JoE95VHXFuBKRFxsYLvWcZV7HknHgCeB1ZJmgNeAuwEi4jDwKbAdmAb+Ap5vq1jrlsrwRMTuivkBvNRYRbZk+AyzpTk8lubwWJrDY2kOj6U5PJbm8Fiaw2NpDo+lOTyW5vBYmsNjaQ6PpTk8lubwWJrDY2kOj6U5PJbm8Fiaw2NpDo+lOTyW5vBYWq3wSNoq6ceyB88rA+bvlTQr6Zvy8ULzpVrX1PnF6DLgbeBpit+ln5E0GRHfz1v0eEQcaKFG66g6e57HgemI+Dki/gY+oujJY3e4OuGp23/nmbKt3AlJawfMtxFTJzx1+u98AqyLiMeAL4APBm5IGpfUl9SfnZ1dXKXWOXXCU9l/JyJ+j4ir5eS7wOZBG4qIiYjoRURvzZpF9xKyjqkTnjPABkkPS1oB7KLoyXPdvB6EO4AfmivRuqpOi5Vrkg4AnwPLgCMRcV7SQaAfEZPAy5J2ANcoml/ubbFm6wgN65ZJbivXHZKmIqK32PV8htnSHB5Lc3gszeGxNIfH0hweS3N4LM3hsTSHx9IcHktzeCzN4bE0h8fSHB5Lc3gszeGxNIfH0hweS3N4LM3hsTSHx9IcHktzeCytqf4890g6Xs4/LWld04Va91SGZ05/nm3ARmC3pI3zFtsH/BkRjwBvAm80Xah1T1P9eXbyX2eME8BTkgZ117AR0lR/nuvLRMQ14ApwfxMFWndVNjqgXn+eOssgaRwYLyevSjpX4/27bDVwedhFNODRzEp1wlPZn2fOMjOSlgP3UXTLuEFETAATAJL6mR/Xd8kojAGKcWTWa6Q/Tzn9XPn8WeDLGFb7DbttmurP8x7woaRpij3OrjaLtm4YWn8eSePlx9iSNQpjgPw4hhYeW/p8ecLSWg/PKFzaGIXbJ0g6IunSzU6PqHCoHONZSZsqNxoRrT0ovmBfANYDK4BvgY3zlnkROFw+30VxG4JW62phDHuBt4Zda8U4ngA2AeduMn878BnFObstwOmqbba95xmFSxsjcfuEiDjJgHNvc+wEjkbhFLBqXovk/2k7PKNwaeNOuX1C3XFe13Z4Gru0MUSN3T6h4xb9d2g7PIu5tMFClzaGqLHbJ3Rcnb/VDdoOzyhc2rhTbp8wCewpj7q2AFci4uKCa9yGb/nbgZ8ojlheLV87COwon98LfAxMA18D64d9ZJIYw+vAeYojsa+AsWHXPGAMx4CLwD8Ue5l9wH5gfzlfFP/0dwH4DuhVbdNnmC3NZ5gtzeGxNIfH0hweS3N4LM3hsTSHx9IcHkv7FyqzOWDK9CHBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "incorrect = np.where(predicted_classes!=Y_test)[0]\n",
    "print (\"Found %d incorrect labels\" % len(incorrect))\n",
    "for i, incorrect in enumerate(incorrect[:9]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(X_test[incorrect].reshape(29,1), cmap='gray', interpolation='none')\n",
    "    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[incorrect], Y_test[incorrect]))\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-148-029feb1cca49>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtarget_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"Class {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = [\"Class {}\".format(i) for i in range(num_classes)]\n",
    "print(classification_report(Y_test, predicted_classes, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
