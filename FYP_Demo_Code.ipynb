{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import IPython.display as ipd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We’ll process dataset as per our requirements. \n",
    "#We’ll create a CSV file with the data we required.\n",
    "header = 'Filename Chromagram RootMeanSquare LowEnergyBrightness SpectralCentroid Flatness Bandwidth InHarmonicity Rolloff ZeroCrossingRate'\n",
    "for i in range(1,21):\n",
    "        header += f' mfcc{i}'\n",
    "header += ' label'\n",
    "header = header.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\scipy\\sparse\\lil.py:514: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not j.flags.writeable or j.dtype not in (np.int32, np.int64):\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\scipy\\sparse\\lil.py:514: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not j.flags.writeable or j.dtype not in (np.int32, np.int64):\n"
     ]
    }
   ],
   "source": [
    "#If you have read the blog of features extraction \n",
    "#we’ll get 20 mfcc for given sampling rate because\n",
    "#it is calculated for each frame so mfcc has 20 columns.\n",
    "#Now, we’ll calculate all the features.\n",
    "file = open('extractedmusicfeatureset.csv', 'w', newline='')\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "genres = 'blues classical country disco hiphop jazz metal pop reggae rock'.split()\n",
    "for g in genres:\n",
    "    for filename in os.listdir(f'./genres/{g}'):\n",
    "        songname = f'./genres/{g}/{filename}'\n",
    "        y, sr = librosa.load(songname, mono=True, duration=30)\n",
    "        y = librosa.effects.harmonic(y)\n",
    "        chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)#chromagram\n",
    "        rms = librosa.feature.rms(y=y)#root-mean square\n",
    "        spec_cont = librosa.feature.spectral_contrast(y=y, sr=sr)#low energy/brightness\n",
    "        spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)#spectral centroid\n",
    "        spec_flat = librosa.feature.spectral_flatness(y=y)#flatness\n",
    "        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)#bandwidth\n",
    "        tone = librosa.feature.tonnetz(y=y, sr=sr)#In-Harmonicity\n",
    "        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)#rolloff\n",
    "        zcr = librosa.feature.zero_crossing_rate(y)#zero-crossing rate\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "        to_append = f'{filename} {np.mean(chroma_stft)} {np.mean(rms)} {np.mean(spec_cont)} {np.mean(spec_cent)} {np.mean(spec_flat)} {np.mean(spec_bw)} {np.mean(tone)} {np.mean(rolloff)} {np.mean(zcr)}'\n",
    "        for e in mfcc:\n",
    "            to_append += f' {np.mean(e)}'\n",
    "        to_append += f' {g}'\n",
    "        file = open('extractedmusicfeatureset.csv', 'a', newline='')\n",
    "        with file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(to_append.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Split audio files goes here when refactored##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unneccesary columns\n",
    "data = pd.read_csv('data_test_two.csv')\n",
    "data = data.drop(['filename'],axis=1) #Filename is not required\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Chromagram','RootMeanSquare','LowEnergyBrightness','SpectralCentroid','Flatness','Bandwidth','InHarmonicity','Rolloff','ZeroCrossingRate','mfcc1','mfcc2','mfcc3','mfcc4','mfcc5','mfcc6','mfcc7','mfcc8','mfcc9','mfcc10','mfcc11','mfcc12','mfcc13','mfcc14','mfcc15','mfcc16','mfcc17','mfcc18','mfcc19','mfcc20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_prenorm = data[features]\n",
    "pd.DataFrame(X_prenorm,columns=features).hist(figsize=(8,8), normed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#maybe should be X_prenorm.groupby instead\n",
    "genre_count = data.groupby('label').agg({'label':'count'})['label']\n",
    "print(genre_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = Normalizer()\n",
    "data[features] = norm.fit_transform(data[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_groupby = data.groupby('label').agg('mean')\n",
    "clusters = genre_groupby.reset_index().rename({'label':'cluster'}, axis=1)\n",
    "clusters['method'] = 'Mean'\n",
    "\n",
    "oldclusters = clusters\n",
    "oldclusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[features].hist(figsize=(8,8), normed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['Chromagram','RootMeanSquare','LowEnergyBrightness','SpectralCentroid','Flatness','Bandwidth','InHarmonicity','Rolloff','ZeroCrossingRate']]\n",
    "\n",
    "Ks = np.arange(1, 20)\n",
    "km = [KMeans(n_clusters=i, random_state=1986) for i in Ks]\n",
    "score = [-km[i].fit(X).score(X) for i in range(len(km))]\n",
    "Ks.dtype = int\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(Ks,score)\n",
    "plt.xlim(0,18)\n",
    "plt.grid(True)\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Elbow Method')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ks = np.arange(2, 30)\n",
    "kms = [KMeans(n_clusters=i, random_state=1986).fit(X) for i in Ks]\n",
    "s_scores = [silhouette_score(X,kms[i].labels_) for i in range(2,len(Ks))]\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(Ks[2:len(Ks)],s_scores)\n",
    "#plt.xlim(0,18)\n",
    "plt.grid(True)\n",
    "plt.xlabel('K')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['Chromagram','RootMeanSquare','LowEnergyBrightness','SpectralCentroid','Flatness','Bandwidth','InHarmonicity','Rolloff','ZeroCrossingRate']]\n",
    "km = KMeans(n_clusters=len(genre_groupby), n_init=10, random_state=1986)\n",
    "km.fit(X)\n",
    "labels = km.labels_\n",
    "cluster_centers = km.cluster_centers_\n",
    "labels_unique = np.unique(labels)\n",
    "n_clusters_ = len(labels_unique)\n",
    "km_clusters = pd.DataFrame(cluster_centers, columns=features)\n",
    "km_clusters['cluster'] = ['KM{}'.format(l) for l in labels_unique]\n",
    "km_clusters['method'] = 'KMeans'\n",
    "oldclusters = pd.concat([oldclusters, km_clusters])\n",
    "cols = ['cluster'] + features + ['method']\n",
    "oldclusters = oldclusters[cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newclusters = oldclusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newclusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "sns.set(font_scale=1.5)\n",
    "sns.heatmap(\n",
    "    data=newclusters.loc[newclusters.method=='KMeans', features],\n",
    "    cmap='Purples',\n",
    "    annot=True\n",
    ")\n",
    "plt.ylabel(\"KMeansLabel\")\n",
    "plt.savefig('heatmap_all.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distances = [abs(np.linalg.norm(genre_coordinates-c)) for c in genre_coordinates_other]\n",
    "### Assign K-Means Label to Descriptive Labels\n",
    "descriptive_labels = [\"Slow & Somber Acoustics\", \"Sad Instrumentals\", \"Upbeat Songs With Cheerful Vocals\", \n",
    "                      \"Fast & Danceable Instrumentals\", \"Fast, Upbeat & Cheerful Songs\", \"Happy & Upbeat Instrumentals\",\n",
    "                      \"Aggressive, Fast Paced Acoustics\", \"Slow Happy Dance\", \"Happy & Slow\", \"Fast, Upbeat & Cheerful Acoustics\"]\n",
    "\n",
    "descriptive_labels = [\"Slow & Somber Acoustics\",\"Sad Instrumentals\", \"Upbeat Songs With Cheerful Vocals\", \n",
    "                      \"Fast & Danceable Instrumentals\", \"Fast, Upbeat & Cheerful Songs\", \"Happy & Upbeat Instrumentals\",\n",
    "                      \"Aggressive, Fast Paced Acoustics\", \"Slow Happy Dance\", \"Happy & Slow\", \"Fast, Upbeat & Cheerful Acoustics\"]\n",
    "unique_labels = np.unique(labels)\n",
    "translated_labels = dict(zip(unique_labels, descriptive_labels))\n",
    "data['KMeansLabel'] = list(map(lambda x:translated_labels[x], labels))\n",
    "################################################################################\n",
    "#####################TRy other clustering algorithms############################\n",
    "################################################################################\n",
    "\n",
    "genre_count = data.groupby('label').agg({'label':'count'})['label']\n",
    "\n",
    "# How many instances of each k-means cluster are there?\n",
    "print(\"### Instances of KMeans Cluster ###\")\n",
    "print(data[['label', 'KMeansLabel']].groupby('KMeansLabel').agg('count'))\n",
    "\n",
    "# Which cluster corresponds to the most instances per genre?\n",
    "print(\"### Which cluster corresponds to the most instances per genre? ###\")\n",
    "print(data[['label', 'KMeansLabel']].groupby('label').agg(lambda x:x.value_counts().index[0]))\n",
    "\n",
    "# Which genre corresponds to the most instances per cluster?\n",
    "print(\"### Which genre corresponds to the most instances per cluster? ###\")\n",
    "print(data[['label', 'KMeansLabel']].groupby('KMeansLabel').agg(lambda x:x.value_counts().index[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_new = pca.fit_transform(X)\n",
    "x,y = zip(*X_new)\n",
    "data['x'] = x\n",
    "data['y'] = y\n",
    "components = pca.components_\n",
    "explained_variance = pca.explained_variance_\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "singular_values = pca.singular_values_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_components = dict(list(zip(features, zip(*np.round(components,2)))))\n",
    "audio_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "singular_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.5)\n",
    "sns.lmplot(data=data, x='x', y='y', hue='label', fit_reg=False, legend=True, size=8, palette='Set1',\n",
    "           scatter_kws={'alpha':0.35, 's':25})\n",
    "plt.savefig('pca_scatter_genres.png')\n",
    "plt.title(\"Clustering by Genre, Reduced Dimension\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.5)\n",
    "sns.lmplot(data=data, x='x', y='y', hue='KMeansLabel', fit_reg=False, legend=True, size=8, palette='Set1',\n",
    "           scatter_kws={'alpha':0.35, 's':25})\n",
    "plt.title(\"Clustering by KMeans Label, Reduced Dimension\")\n",
    "plt.savefig('pca_scatter_KM.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Confusion Matrix goes here when complete##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
